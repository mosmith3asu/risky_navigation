
ALGORITHM COMPARISON SUMMARY REPORT (WITH HYPERPARAMETER TUNING)
Generated on: 2025-10-10 20:39:04
================================================================================

EXPERIMENTAL SETUP:
- Number of training episodes: 1000
- Training epochs per algorithm: 700
- Batch size: 128
- Test episodes: 50
- Device: cuda

HYPERPARAMETER TUNING SETUP:
- Search method: grid
- Number of trials per algorithm: 10
- Cross-validation folds: 3
- Early stopping patience: 3
- HP search epochs: 50

RESULTS RANKING:

1. Best Overall Performance (Average Reward):
   VAE - -56.985
   Best hyperparams: {'beta': 2.0, 'hidden_dim': 256, 'latent_dim': 16, 'lr': 0.01}

2. Most Accurate Predictions (Lowest MSE):
   VAE - 0.215760
   Best hyperparams: {'beta': 2.0, 'hidden_dim': 256, 'latent_dim': 16, 'lr': 0.01}

3. Highest Success Rate:
   VAE - 0.000
   Best hyperparams: {'beta': 2.0, 'hidden_dim': 256, 'latent_dim': 16, 'lr': 0.01}

4. Fastest Training:
   VAE - 143.04s
   Best hyperparams: {'beta': 2.0, 'hidden_dim': 256, 'latent_dim': 16, 'lr': 0.01}

5. Best Validation Performance:
   VAE - 0.214343
   Best hyperparams: {'beta': 2.0, 'hidden_dim': 256, 'latent_dim': 16, 'lr': 0.01}

6. Best Cross-Validation Score (from hyperparameter search):
   VAE - 0.218155

DETAILED RESULTS:
algorithm  avg_reward  avg_mse  success_rate  train_time  hp_search_cv_score
      VAE  -56.984504  0.21576           0.0  143.044017            0.218155

HYPERPARAMETER DETAILS:

VAE:
  Best hyperparameters: {'beta': 2.0, 'hidden_dim': 256, 'latent_dim': 16, 'lr': 0.01}
  HP search CV score: 0.218155
  Final validation loss: 0.214343
  Model parameters: 279,586


RECOMMENDATIONS:
- For real-time applications: Choose the algorithm with fastest training/inference
- For accuracy-critical tasks: Choose the algorithm with lowest MSE
- For exploration tasks: Choose the algorithm with highest success rate
- For resource-constrained environments: Choose the algorithm with fewest parameters
- For robust performance: Consider the algorithm with best cross-validation score

METHODOLOGY NOTES:
- All algorithms underwent 3-fold cross-validation hyperparameter tuning
- Best hyperparameters were selected based on validation loss minimization
- Final models were trained with full epochs using the best hyperparameters
- This ensures fair comparison and optimal performance for each algorithm
