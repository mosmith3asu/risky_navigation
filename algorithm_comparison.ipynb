{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "578ac5ae",
   "metadata": {},
   "source": [
    "# Operator Action Prediction for Teleoperation with Communication Delays\n",
    "\n",
    "This notebook compares neural network architectures for predicting operator actions during communication delays in space teleoperation scenarios.\n",
    "\n",
    "## Problem Context\n",
    "\n",
    "**Space teleoperation faces critical communication delays:**\n",
    "- Mars missions: up to 22 minutes round-trip delay\n",
    "- Moon missions: 1.25 seconds one-way delay\n",
    "- Operators cannot respond to obstacles in real-time\n",
    "\n",
    "**Our Approach:**\n",
    "Learn forward models that predict operator actions based on:\n",
    "- Current state (robot position, velocity, orientation)\n",
    "- Goal position\n",
    "- Historical action sequences (for Transformer)\n",
    "\n",
    "## Algorithms Evaluated\n",
    "\n",
    "1. **Linear Regression** - Simple baseline `state → action`\n",
    "2. **Bayesian Neural Network** - Uncertainty-aware predictions with probabilistic weights\n",
    "3. **VAE (Variational AutoEncoder)** - Latent action distribution modeling\n",
    "4. **Transformer** - Self-attention over temporal sequences `[s_t-k, ..., s_t] → a_t`\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. **Data Collection**: Expert demonstrations from optimal visibility graph policy\n",
    "2. **Model Training**: Supervised learning (behavioral cloning) with grid search\n",
    "3. **Evaluation**: Test models in environment using predicted actions\n",
    "4. **Analysis**: Compare prediction accuracy, uncertainty quantification, computational efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7077109",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3f6497",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas matplotlib seaborn scikit-learn torch torchvision torchaudio gymnasium tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2cea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "print(os.path.abspath('.'))\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c632d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/risky_navigation')\n",
    "\n",
    "from src.env.continuous_nav_env import ContinuousNavigationEnv\n",
    "from src.algorithms.Bayesian.agent import BayesianAgent\n",
    "from src.algorithms.Transformer.agent import TransformerAgent\n",
    "from src.algorithms.Linear.agent import LinearAgent\n",
    "from src.algorithms.VAE.agent import VAEAgent\n",
    "from src.utils.file_management import save_pickle, load_pickle\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device available: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57817ec8",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a17c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'num_episodes': 1000,\n",
    "    'max_steps': 200,\n",
    "    'batch_size': 512,  # Increased for RTX 4090\n",
    "    'num_epochs': 200,\n",
    "    'val_ratio': 0.2,\n",
    "    'num_test_episodes': 50,\n",
    "    'lr': 1e-3,\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'num_workers': 4,  # Parallel data loading\n",
    "    'prefetch_factor': 2,\n",
    "}\n",
    "\n",
    "# Grid search configurations for each algorithm\n",
    "GRID_SEARCH_CONFIGS = {\n",
    "    'Transformer': {\n",
    "        'd_model': [32, 64, 128],\n",
    "        'nhead': [4, 8],\n",
    "        'num_layers': [2, 3, 4],\n",
    "        'dropout': [0.0, 0.1, 0.2],\n",
    "        'sequence_len': [1, 5, 10],  # Added: temporal sequence length for time-series modeling\n",
    "        'lr': [1e-3, 5e-4, 1e-4]\n",
    "    },\n",
    "    'Bayesian': {\n",
    "        'hidden_dim': [64, 128, 256],\n",
    "        'prior_std': [0.5, 1.0, 2.0],\n",
    "        'kl_weight': [1e-5, 1e-4, 1e-3],  # Added: KL divergence weight for ELBO\n",
    "        'lr': [1e-3, 5e-4, 1e-4]\n",
    "    },\n",
    "    'VAE': {\n",
    "        'latent_dim': [16, 32, 64],\n",
    "        'hidden_dim': [64, 128, 256],\n",
    "        'beta': [0.5, 1.0, 2.0],\n",
    "        'lr': [1e-3, 5e-4, 1e-4]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Best baseline configs (for quick comparison)\n",
    "MODEL_CONFIGS = {\n",
    "    'Linear': {},\n",
    "    'Transformer': {'d_model': 64, 'nhead': 4, 'num_layers': 2, 'dropout': 0.1, 'sequence_len': 1},\n",
    "    'Bayesian': {'hidden_dim': 128, 'prior_std': 1.0, 'kl_weight': 1e-5},\n",
    "    'VAE': {'latent_dim': 32, 'hidden_dim': 128, 'beta': 1.0}\n",
    "}\n",
    "\n",
    "print(f\"Using device: {CONFIG['device']}\")\n",
    "print(f\"Batch size: {CONFIG['batch_size']} (optimized for RTX 4090)\")\n",
    "print(f\"Max epochs: {CONFIG['num_epochs']} (with early stopping)\")\n",
    "print(f\"Grid search enabled for: {list(GRID_SEARCH_CONFIGS.keys())}\")\n",
    "print(f\"\\nTransformer will test sequence lengths: {GRID_SEARCH_CONFIGS['Transformer']['sequence_len']}\")\n",
    "print(f\"  - sequence_len=1: Single state\")\n",
    "print(f\"  - sequence_len>1: Temporal sequences (time-series modeling)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # RTX 4090 optimizations\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "    \n",
    "    # Enable cuDNN autotuner for optimal convolution algorithms\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    \n",
    "    # Memory optimizations\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Mixed precision training setup\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    use_amp = True\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"GPU OPTIMIZATIONS ENABLED FOR RTX 4090\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"✓ Batch size: {CONFIG['batch_size']}\")\n",
    "    print(f\"✓ TF32 matmul: Enabled\")\n",
    "    print(f\"✓ cuDNN benchmark: Enabled\")\n",
    "    print(f\"✓ Mixed precision (AMP): Enabled\")\n",
    "    print(f\"✓ CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"✓ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"✓ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    use_amp = False\n",
    "    scaler = None\n",
    "    print(\"WARNING: CUDA not available. Running on CPU will be very slow!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39622191",
   "metadata": {},
   "source": [
    "## Training Functions with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2b379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent_optimized(agent, train_states, train_expert_actions, train_goals,\n",
    "                          val_states, val_expert_actions, val_goals, \n",
    "                          num_epochs=100, batch_size=256, device='cpu', use_amp=False, \n",
    "                          scaler=None, verbose=True):\n",
    "    \"\"\"Optimized training with mixed precision, early stopping, LR scheduling, and gradient clipping.\"\"\"\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    n_train = len(train_states)\n",
    "    \n",
    "    # Early stopping\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 15\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    # Learning rate scheduler with warmup\n",
    "    if hasattr(agent, 'optimizer'):\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            agent.optimizer, \n",
    "            max_lr=agent.optimizer.param_groups[0]['lr'] * 10,\n",
    "            epochs=num_epochs,\n",
    "            steps_per_epoch=(n_train + batch_size - 1) // batch_size,\n",
    "            pct_start=0.3,\n",
    "            anneal_strategy='cos'\n",
    "        )\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        num_batches = 0\n",
    "        indices = np.random.permutation(n_train)\n",
    "        \n",
    "        for start_idx in range(0, n_train, batch_size):\n",
    "            end_idx = min(start_idx + batch_size, n_train)\n",
    "            batch_indices = indices[start_idx:end_idx]\n",
    "            \n",
    "            batch_states = torch.tensor(train_states[batch_indices], dtype=torch.float32, device=device)\n",
    "            batch_actions = torch.tensor(train_expert_actions[batch_indices], dtype=torch.float32, device=device)\n",
    "            \n",
    "            # Mixed precision training (only if optimizer exists and loss is tensor)\n",
    "            if use_amp and scaler is not None and hasattr(agent, 'optimizer'):\n",
    "                with autocast():\n",
    "                    loss = agent.train_step(batch_states, None, None, batch_actions)\n",
    "                \n",
    "                # Check if loss is a tensor (some agents return float after backward)\n",
    "                if isinstance(loss, torch.Tensor):\n",
    "                    agent.optimizer.zero_grad()\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.unscale_(agent.optimizer)\n",
    "                    \n",
    "                    # Gradient clipping\n",
    "                    if hasattr(agent, 'model'):\n",
    "                        torch.nn.utils.clip_grad_norm_(agent.model.parameters(), 1.0)\n",
    "                    elif hasattr(agent, 'encoder'):\n",
    "                        torch.nn.utils.clip_grad_norm_(\n",
    "                            list(agent.encoder.parameters()) + list(agent.decoder.parameters()), 1.0\n",
    "                        )\n",
    "                    \n",
    "                    scaler.step(agent.optimizer)\n",
    "                    scaler.update()\n",
    "                    scheduler.step()\n",
    "                    \n",
    "                    loss = loss.item()\n",
    "                else:\n",
    "                    # Loss already computed and stepped inside train_step\n",
    "                    scheduler.step()\n",
    "            else:\n",
    "                # Standard training (no AMP)\n",
    "                loss = agent.train_step(batch_states, None, None, batch_actions)\n",
    "                \n",
    "                # Gradient clipping (if optimizer exists and hasn't been stepped yet)\n",
    "                if hasattr(agent, 'optimizer') and isinstance(loss, torch.Tensor):\n",
    "                    if hasattr(agent, 'model'):\n",
    "                        torch.nn.utils.clip_grad_norm_(agent.model.parameters(), 1.0)\n",
    "                    elif hasattr(agent, 'encoder'):\n",
    "                        torch.nn.utils.clip_grad_norm_(\n",
    "                            list(agent.encoder.parameters()) + list(agent.decoder.parameters()), 1.0\n",
    "                        )\n",
    "                    scheduler.step()\n",
    "                \n",
    "                # Convert tensor to float if needed\n",
    "                if isinstance(loss, torch.Tensor):\n",
    "                    loss = loss.item()\n",
    "            \n",
    "            epoch_loss += loss\n",
    "            num_batches += 1\n",
    "        \n",
    "        avg_train_loss = epoch_loss / num_batches\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        val_states_t = torch.tensor(val_states, dtype=torch.float32, device=device)\n",
    "        val_actions_t = torch.tensor(val_expert_actions, dtype=torch.float32, device=device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if hasattr(agent, 'model'):\n",
    "                agent.model.eval()\n",
    "                predictions = agent.model(val_states_t)\n",
    "                agent.model.train()\n",
    "            elif hasattr(agent, 'encoder'):\n",
    "                agent.encoder.eval()\n",
    "                agent.decoder.eval()\n",
    "                mu, _ = agent.encoder(val_states_t)\n",
    "                predictions = agent.decoder(mu)\n",
    "                agent.encoder.train()\n",
    "                agent.decoder.train()\n",
    "            else:\n",
    "                predictions = agent.predict_action(val_states_t, None)\n",
    "            \n",
    "            val_loss = torch.nn.functional.mse_loss(predictions, val_actions_t).item()\n",
    "        \n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            # Save best model\n",
    "            if hasattr(agent, 'model'):\n",
    "                best_model_state = agent.model.state_dict().copy()\n",
    "            elif hasattr(agent, 'encoder'):\n",
    "                best_model_state = {\n",
    "                    'encoder': agent.encoder.state_dict().copy(),\n",
    "                    'decoder': agent.decoder.state_dict().copy()\n",
    "                }\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                if verbose:\n",
    "                    print(f\"Early stop at epoch {epoch}. Best val: {best_val_loss:.6f}\")\n",
    "                # Restore best\n",
    "                if best_model_state:\n",
    "                    if hasattr(agent, 'model'):\n",
    "                        agent.model.load_state_dict(best_model_state)\n",
    "                    elif hasattr(agent, 'encoder'):\n",
    "                        agent.encoder.load_state_dict(best_model_state['encoder'])\n",
    "                        agent.decoder.load_state_dict(best_model_state['decoder'])\n",
    "                break\n",
    "        \n",
    "        if verbose and (epoch % 10 == 0 or epoch == num_epochs - 1):\n",
    "            current_lr = agent.optimizer.param_groups[0]['lr'] if hasattr(agent, 'optimizer') else 0\n",
    "            print(f\"Epoch {epoch:3d}/{num_epochs}: Train={avg_train_loss:.6f}, Val={val_loss:.6f}, LR={current_lr:.6f}\")\n",
    "            \n",
    "            if np.isnan(avg_train_loss) or np.isnan(val_loss):\n",
    "                print(f\"WARNING: NaN at epoch {epoch}!\")\n",
    "                break\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "print(\"Optimized training function with mixed precision ready!\")\n",
    "print(\"Fixed: Handles both tensor and float returns from train_step()\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d212700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def grid_search_algorithm(AgentClass, algo_name, grid_params, \n",
    "                          train_states, train_actions, train_goals,\n",
    "                          val_states, val_actions, val_goals,\n",
    "                          state_dim, action_dim, device, use_amp, scaler):\n",
    "    \"\"\"\n",
    "    Perform grid search for a single algorithm.\n",
    "    Returns: list of (config, agent, train_losses, val_losses, val_loss, train_time)\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"GRID SEARCH: {algo_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Generate all combinations\n",
    "    param_names = list(grid_params.keys())\n",
    "    param_values = [grid_params[k] for k in param_names]\n",
    "    all_configs = list(itertools.product(*param_values))\n",
    "    \n",
    "    print(f\"Total configurations to test: {len(all_configs)}\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for idx, config_values in enumerate(all_configs, 1):\n",
    "        config = dict(zip(param_names, config_values))\n",
    "        \n",
    "        # Extract learning rate if present\n",
    "        lr = config.pop('lr', CONFIG['lr'])\n",
    "        \n",
    "        print(f\"\\n[{idx}/{len(all_configs)}] Testing config: {config}\")\n",
    "        \n",
    "        try:\n",
    "            # Create agent with this config\n",
    "            agent = AgentClass(\n",
    "                state_dim=state_dim,\n",
    "                action_dim=action_dim,\n",
    "                lr=lr,\n",
    "                device=device,\n",
    "                **config\n",
    "            )\n",
    "            \n",
    "            # Train\n",
    "            start_time = time.time()\n",
    "            train_losses, val_losses = train_agent_optimized(\n",
    "                agent, \n",
    "                train_states, train_actions, train_goals,\n",
    "                val_states, val_actions, val_goals,\n",
    "                num_epochs=CONFIG['num_epochs'],\n",
    "                batch_size=CONFIG['batch_size'],\n",
    "                device=device,\n",
    "                use_amp=use_amp,\n",
    "                scaler=scaler,\n",
    "                verbose=False\n",
    "            )\n",
    "            train_time = time.time() - start_time\n",
    "            \n",
    "            final_val_loss = val_losses[-1]\n",
    "            \n",
    "            # Store complete config including lr\n",
    "            full_config = {**config, 'lr': lr}\n",
    "            results.append((full_config, agent, train_losses, val_losses, final_val_loss, train_time))\n",
    "            \n",
    "            print(f\"  ✓ Val Loss: {final_val_loss:.6f}, Time: {train_time:.1f}s\")\n",
    "            \n",
    "            # Clear GPU cache\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Failed: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Sort by validation loss\n",
    "    results.sort(key=lambda x: x[4])\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"GRID SEARCH COMPLETE: {algo_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Best config: {results[0][0]}\")\n",
    "    print(f\"Best val loss: {results[0][4]:.6f}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Grid search function ready!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1652df29",
   "metadata": {},
   "source": [
    "## Data Collection and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7f97ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_rl_experience(env, num_episodes=100, max_steps=200):\n",
    "    \"\"\"Collect RL training data using optimal policy with proper goal stopping.\"\"\"\n",
    "    data = []\n",
    "    successful_episodes = 0\n",
    "    \n",
    "    for ep in tqdm(range(num_episodes), desc='Collecting RL experience'):\n",
    "        state = env.reset()\n",
    "        goal = env.goal.copy() if hasattr(env, 'goal') else np.zeros(2)\n",
    "        \n",
    "        for t in range(max_steps):\n",
    "            current_pos = state[:2]\n",
    "            current_theta = state[2]\n",
    "            current_velocity = state[3]  # Current velocity from state\n",
    "            dist_to_goal = np.linalg.norm(current_pos - goal)\n",
    "            \n",
    "            # Calculate desired heading towards goal\n",
    "            direction = goal - current_pos\n",
    "            desired_theta = np.arctan2(direction[1], direction[0])\n",
    "            angle_diff = desired_theta - current_theta\n",
    "            angle_diff = (angle_diff + np.pi) % (2 * np.pi) - np.pi\n",
    "            steering = np.clip(angle_diff, env.action_space.low[1], env.action_space.high[1])\n",
    "            \n",
    "            # IMPROVED THROTTLE CONTROL: Gradual deceleration near goal\n",
    "            # Goal requires: distance <= 0.5 AND velocity < 0.1\n",
    "            if dist_to_goal < env.goal_radius * 3:  # Within 1.5 units of goal\n",
    "                # Proportional throttle based on distance\n",
    "                # At distance 1.5: throttle = 0.3 * max\n",
    "                # At distance 0.5: throttle = 0.1 * max  \n",
    "                # At distance 0.0: throttle = 0.0\n",
    "                throttle_factor = max(0.0, min(1.0, (dist_to_goal / (env.goal_radius * 3)) * 0.3))\n",
    "                throttle = env.action_space.high[0] * throttle_factor\n",
    "            else:\n",
    "                # Full speed when far from goal\n",
    "                throttle = env.action_space.high[0]\n",
    "            \n",
    "            # If very close and moving slowly, stop completely\n",
    "            if dist_to_goal < env.goal_radius and current_velocity < env.goal_velocity * 1.5:\n",
    "                throttle = 0.0\n",
    "                steering = 0.0\n",
    "            \n",
    "            action = np.array([throttle, steering])\n",
    "            action = np.clip(action, env.action_space.low, env.action_space.high)\n",
    "            \n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            data.append({\n",
    "                'state': state.copy(),\n",
    "                'action': action.copy(),\n",
    "                'reward': reward,\n",
    "                'next_state': next_state.copy(),\n",
    "                'done': done,\n",
    "                'goal': goal.copy()\n",
    "            })\n",
    "            \n",
    "            state = next_state\n",
    "            \n",
    "            if done:\n",
    "                if info.get('reason') == 'goal_reached':\n",
    "                    successful_episodes += 1\n",
    "                break\n",
    "    \n",
    "    print(f\"Collected {len(data)} transitions from {num_episodes} episodes\")\n",
    "    print(f\"Success rate: {successful_episodes/num_episodes:.2%}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "print(\"Data collection function defined!\")\n",
    "print(\"IMPROVED: Gradual deceleration with proportional throttle control near goal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a347d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or collect data\n",
    "dataset_path = 'rl_experience_dataset.pickle'\n",
    "\n",
    "if os.path.exists(dataset_path):\n",
    "    print(f\"Loading existing dataset from {dataset_path}...\")\n",
    "    data = load_pickle(dataset_path)\n",
    "    print(f\"✓ Loaded {len(data)} transitions\")\n",
    "else:\n",
    "    print(f\"Collecting new dataset...\")\n",
    "    env_collect = ContinuousNavigationEnv()\n",
    "    data = collect_rl_experience(env_collect, num_episodes=CONFIG['num_episodes'], max_steps=CONFIG['max_steps'])\n",
    "    save_pickle(data, dataset_path)\n",
    "    print(f\"✓ Saved dataset to {dataset_path}\")\n",
    "\n",
    "# Extract states, actions, and goals from data\n",
    "states = np.array([d['state'] for d in data])\n",
    "actions = np.array([d['action'] for d in data])\n",
    "next_states = np.array([d['next_state'] for d in data])\n",
    "rewards = np.array([d['reward'] for d in data])\n",
    "dones = np.array([d['done'] for d in data])\n",
    "goals = np.array([d['goal'] for d in data])\n",
    "\n",
    "print(f\"\\nDataset Summary:\")\n",
    "print(f\"  Total transitions: {len(data)}\")\n",
    "print(f\"  States shape: {states.shape}\")\n",
    "print(f\"  Actions shape: {actions.shape}\")\n",
    "print(f\"  Success rate: {dones.sum() / len(dones):.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437071f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dimensions and initialize environment\n",
    "STATE_DIM = states.shape[1]\n",
    "ACTION_DIM = actions.shape[1]\n",
    "env = ContinuousNavigationEnv()\n",
    "\n",
    "print(f\"Environment & Data Configuration:\")\n",
    "print(f\"  STATE_DIM = {STATE_DIM}\")\n",
    "print(f\"  ACTION_DIM = {ACTION_DIM}\")\n",
    "print(f\"  Total samples = {len(states)}\")\n",
    "print(f\"  State space: {env.observation_space.shape}\")\n",
    "print(f\"  Action space: {env.action_space.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d49cc82",
   "metadata": {},
   "source": [
    "## Grid Search Training - All Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9da6b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"GRID SEARCH TRAINING - ALL ALGORITHMS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Split data\n",
    "n_samples = len(states)\n",
    "n_train = int(n_samples * (1 - CONFIG['val_ratio']))\n",
    "indices = np.random.permutation(n_samples)\n",
    "train_indices = indices[:n_train]\n",
    "val_indices = indices[n_train:]\n",
    "\n",
    "train_states = states[train_indices]\n",
    "train_actions = actions[train_indices]\n",
    "train_goals = goals[train_indices]\n",
    "\n",
    "val_states = states[val_indices]\n",
    "val_actions = actions[val_indices]\n",
    "val_goals = goals[val_indices]\n",
    "\n",
    "print(f\"Data split: {len(train_states)} train, {len(val_states)} val\")\n",
    "print(f\"Mixed precision: {use_amp}\")\n",
    "print(f\"Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"Max epochs: {CONFIG['num_epochs']}\\n\")\n",
    "\n",
    "# Store all grid search results\n",
    "grid_search_results = {}\n",
    "\n",
    "# Algorithms with grid search\n",
    "algorithms_with_grid = {\n",
    "    'Transformer': (TransformerAgent, GRID_SEARCH_CONFIGS['Transformer']),\n",
    "    'Bayesian': (BayesianAgent, GRID_SEARCH_CONFIGS['Bayesian']),\n",
    "    'VAE': (VAEAgent, GRID_SEARCH_CONFIGS['VAE'])\n",
    "}\n",
    "\n",
    "# Train Linear baseline (no grid search needed)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training Linear (Baseline - No Grid Search)\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "linear_agent = LinearAgent(\n",
    "    state_dim=STATE_DIM,\n",
    "    action_dim=ACTION_DIM,\n",
    "    lr=CONFIG['lr'],\n",
    "    device=CONFIG['device']\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "train_losses, val_losses = train_agent_optimized(\n",
    "    linear_agent,\n",
    "    train_states, train_actions, train_goals,\n",
    "    val_states, val_actions, val_goals,\n",
    "    num_epochs=CONFIG['num_epochs'],\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    device=CONFIG['device'],\n",
    "    use_amp=use_amp,\n",
    "    scaler=scaler,\n",
    "    verbose=True\n",
    ")\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "grid_search_results['Linear'] = [{\n",
    "    'config': {},\n",
    "    'agent': linear_agent,\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'final_val_loss': val_losses[-1],\n",
    "    'train_time': train_time\n",
    "}]\n",
    "\n",
    "print(f\"Linear Complete! Val loss: {val_losses[-1]:.6f}, Time: {train_time:.1f}s\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Run grid search for each algorithm\n",
    "for algo_name, (AgentClass, grid_params) in algorithms_with_grid.items():\n",
    "    results = grid_search_algorithm(\n",
    "        AgentClass, algo_name, grid_params,\n",
    "        train_states, train_actions, train_goals,\n",
    "        val_states, val_actions, val_goals,\n",
    "        STATE_DIM, ACTION_DIM, \n",
    "        CONFIG['device'], use_amp, scaler\n",
    "    )\n",
    "    \n",
    "    # Store results as list of dicts for easier access\n",
    "    grid_search_results[algo_name] = [\n",
    "        {\n",
    "            'config': config,\n",
    "            'agent': agent,\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses,\n",
    "            'final_val_loss': final_val_loss,\n",
    "            'train_time': train_time\n",
    "        }\n",
    "        for config, agent, train_losses, val_losses, final_val_loss, train_time in results\n",
    "    ]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"GRID SEARCH COMPLETE - ALL ALGORITHMS!\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Print summary of best configs\n",
    "print(\"\\nBEST CONFIGURATIONS:\")\n",
    "print(f\"{'Algorithm':<15} {'Val Loss':<12} {'Config'}\")\n",
    "print(\"-\" * 80)\n",
    "for algo_name, results_list in grid_search_results.items():\n",
    "    best = results_list[0]  # Already sorted by val loss\n",
    "    config_str = ', '.join([f\"{k}={v}\" for k, v in best['config'].items()])\n",
    "    print(f\"{algo_name:<15} {best['final_val_loss']:<12.6f} {config_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf49a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search Results Visualization\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VISUALIZING GRID SEARCH RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Figure 1: Training and Validation Curves for Top 5 Configs per Algorithm\n",
    "fig1, axes1 = plt.subplots(len(grid_search_results), 2, figsize=(18, 4*len(grid_search_results)))\n",
    "if len(grid_search_results) == 1:\n",
    "    axes1 = axes1.reshape(1, -1)\n",
    "\n",
    "for idx, (algo_name, results_list) in enumerate(grid_search_results.items()):\n",
    "    ax_train = axes1[idx, 0]\n",
    "    ax_val = axes1[idx, 1]\n",
    "    \n",
    "    # Plot top 5 configs\n",
    "    for i, result in enumerate(results_list[:5]):\n",
    "        epochs = range(len(result['train_losses']))\n",
    "        \n",
    "        # Config label with key parameters\n",
    "        if result['config']:\n",
    "            key_params = {k: v for k, v in result['config'].items() if k in ['lr', 'latent_dim', 'd_model', 'hidden_dim']}\n",
    "            config_label = f\"Rank {i+1}: \" + \", \".join([f\"{k}={v}\" for k, v in key_params.items()])\n",
    "        else:\n",
    "            config_label = \"Baseline\"\n",
    "        \n",
    "        ax_train.plot(epochs, result['train_losses'], label=config_label, alpha=0.8, linewidth=2)\n",
    "        ax_val.plot(epochs, result['val_losses'], label=config_label, alpha=0.8, linewidth=2)\n",
    "    \n",
    "    # Configure plots\n",
    "    ax_train.set_xlabel('Epoch', fontsize=11)\n",
    "    ax_train.set_ylabel('Training Loss', fontsize=11)\n",
    "    ax_train.set_title(f'{algo_name} - Training Loss (Top 5 Configs)', fontsize=12, fontweight='bold')\n",
    "    ax_train.legend(fontsize=9, loc='best')\n",
    "    ax_train.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax_train.set_yscale('log')\n",
    "    \n",
    "    ax_val.set_xlabel('Epoch', fontsize=11)\n",
    "    ax_val.set_ylabel('Validation Loss', fontsize=11)\n",
    "    ax_val.set_title(f'{algo_name} - Validation Loss (Top 5 Configs)', fontsize=12, fontweight='bold')\n",
    "    ax_val.legend(fontsize=9, loc='best')\n",
    "    ax_val.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax_val.set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Figure 2: Performance Comparison - Val Loss vs Training Time\n",
    "fig2, ax2 = plt.subplots(1, 1, figsize=(14, 8))\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(grid_search_results)))\n",
    "markers = ['o', 's', '^', 'D']\n",
    "\n",
    "for idx, (algo_name, results_list) in enumerate(grid_search_results.items()):\n",
    "    val_losses = [r['final_val_loss'] for r in results_list[:10]]\n",
    "    train_times = [r['train_time'] for r in results_list[:10]]\n",
    "    \n",
    "    ax2.scatter(train_times, val_losses, s=200, alpha=0.6, \n",
    "               color=colors[idx], marker=markers[idx % len(markers)],\n",
    "               label=algo_name, edgecolors='black', linewidth=1.5)\n",
    "    \n",
    "    # Annotate best config\n",
    "    ax2.annotate(f'{algo_name}\\nBest', \n",
    "                xy=(train_times[0], val_losses[0]),\n",
    "                xytext=(10, 10), textcoords='offset points',\n",
    "                fontsize=9, fontweight='bold',\n",
    "                bbox=dict(boxstyle='round,pad=0.5', facecolor=colors[idx], alpha=0.3),\n",
    "                arrowprops=dict(arrowstyle='->', lw=1.5))\n",
    "\n",
    "ax2.set_xlabel('Training Time (seconds)', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Final Validation Loss', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Grid Search: Validation Loss vs Training Time', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=10, loc='best', framealpha=0.9)\n",
    "ax2.grid(True, alpha=0.3, linestyle='--')\n",
    "ax2.set_yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary tables\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"GRID SEARCH RESULTS - TOP 5 CONFIGS PER ALGORITHM\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "for algo_name, results_list in grid_search_results.items():\n",
    "    print(f\"\\n{algo_name}:\")\n",
    "    print(f\"{'Rank':<6} {'Val Loss':<12} {'Train Loss':<12} {'Time(s)':<10} {'Epochs':<8} {'Config'}\")\n",
    "    print(\"-\" * 120)\n",
    "    \n",
    "    for rank, result in enumerate(results_list[:5], 1):\n",
    "        config_str = ', '.join([f\"{k}={v}\" for k, v in result['config'].items()]) or \"N/A (baseline)\"\n",
    "        final_train_loss = result['train_losses'][-1]\n",
    "        num_epochs = len(result['train_losses'])\n",
    "        \n",
    "        print(f\"{rank:<6} {result['final_val_loss']:<12.6f} {final_train_loss:<12.6f} \"\n",
    "              f\"{result['train_time']:<10.1f} {num_epochs:<8} {config_str}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*120)\n",
    "print(f\"{'Algorithm':<15} {'Configs':<10} {'Best Val':<12} {'Worst Val':<12} {'Avg Val':<12} {'Std Val':<12}\")\n",
    "print(\"-\" * 120)\n",
    "\n",
    "for algo_name, results_list in grid_search_results.items():\n",
    "    val_losses = [r['final_val_loss'] for r in results_list]\n",
    "    print(f\"{algo_name:<15} {len(results_list):<10} {min(val_losses):<12.6f} \"\n",
    "          f\"{max(val_losses):<12.6f} {np.mean(val_losses):<12.6f} {np.std(val_losses):<12.6f}\")\n",
    "\n",
    "print(\"=\"*120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507cee6b",
   "metadata": {},
   "source": [
    "## Evaluate Best Models from Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dfdccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EVALUATING BEST MODELS FROM GRID SEARCH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def evaluate_agent_optimized(agent, env, num_episodes=50, max_steps=200, device='cpu'):\n",
    "    \"\"\"Evaluate agent with detailed metrics.\"\"\"\n",
    "    results = {\n",
    "        'rewards': [], \n",
    "        'successes': [], \n",
    "        'steps': [],\n",
    "        'final_distances': [],\n",
    "        'final_velocities': []\n",
    "    }\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        episode_reward = 0\n",
    "        done = False\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            state_t = torch.tensor(state, dtype=torch.float32, device=device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                action = agent.predict_action(state_t, None)\n",
    "            \n",
    "            if isinstance(action, torch.Tensor):\n",
    "                action = action.cpu().numpy()\n",
    "            \n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            episode_reward += reward\n",
    "            state = next_state\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        results['rewards'].append(episode_reward)\n",
    "        success = info.get('reason', '') == 'goal_reached' if done else False\n",
    "        results['successes'].append(1 if success else 0)\n",
    "        results['steps'].append(step + 1)\n",
    "        \n",
    "        # Track final state metrics\n",
    "        final_dist = np.linalg.norm(state[:2] - env.goal)\n",
    "        final_vel = state[3]\n",
    "        results['final_distances'].append(final_dist)\n",
    "        results['final_velocities'].append(final_vel)\n",
    "    \n",
    "    return {\n",
    "        'avg_reward': np.mean(results['rewards']),\n",
    "        'std_reward': np.std(results['rewards']),\n",
    "        'success_rate': np.mean(results['successes']),\n",
    "        'avg_steps': np.mean(results['steps']),\n",
    "        'avg_final_distance': np.mean(results['final_distances']),\n",
    "        'avg_final_velocity': np.mean(results['final_velocities'])\n",
    "    }\n",
    "\n",
    "eval_results = {}\n",
    "\n",
    "# Evaluate best model from each algorithm\n",
    "for algo_name, results_list in grid_search_results.items():\n",
    "    print(f\"\\nEvaluating {algo_name} (best config)...\")\n",
    "    best_result = results_list[0]\n",
    "    agent = best_result['agent']\n",
    "    \n",
    "    eval_res = evaluate_agent_optimized(\n",
    "        agent, env, \n",
    "        num_episodes=CONFIG['num_test_episodes'],\n",
    "        max_steps=CONFIG['max_steps'],\n",
    "        device=CONFIG['device']\n",
    "    )\n",
    "    \n",
    "    eval_results[algo_name] = eval_res\n",
    "    \n",
    "    print(f\"  Avg Reward: {eval_res['avg_reward']:.3f} ± {eval_res['std_reward']:.3f}\")\n",
    "    print(f\"  Success Rate: {eval_res['success_rate']:.1%}\")\n",
    "    print(f\"  Avg Steps: {eval_res['avg_steps']:.1f}\")\n",
    "    print(f\"  Avg Final Distance: {eval_res['avg_final_distance']:.3f}\")\n",
    "    print(f\"  Avg Final Velocity: {eval_res['avg_final_velocity']:.3f}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"EVALUATION COMPLETE!\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3cc541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Results Table and Visualization\n",
    "import pandas as pd\n",
    "\n",
    "results_data = []\n",
    "for algo_name in grid_search_results.keys():\n",
    "    best_train_res = grid_search_results[algo_name][0]\n",
    "    eval_res = eval_results[algo_name]\n",
    "    \n",
    "    results_data.append({\n",
    "        'Algorithm': algo_name,\n",
    "        'Val Loss': best_train_res['final_val_loss'],\n",
    "        'Train Time (s)': best_train_res['train_time'],\n",
    "        'Success Rate': eval_res['success_rate'],\n",
    "        'Avg Reward': eval_res['avg_reward'],\n",
    "        'Avg Steps': eval_res['avg_steps'],\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results_data)\n",
    "df_results = df_results.sort_values('Val Loss')\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"FINAL RESULTS SUMMARY - BEST CONFIGS FROM GRID SEARCH\")\n",
    "print(\"=\"*100)\n",
    "print(df_results.to_string(index=False))\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Visualization: Performance Comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Success Rate\n",
    "axes[0, 0].bar(df_results['Algorithm'], df_results['Success Rate'], color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_ylabel('Success Rate', fontsize=11)\n",
    "axes[0, 0].set_title('Success Rate by Algorithm', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "axes[0, 0].set_ylim([0, 1.1])\n",
    "\n",
    "# Average Reward\n",
    "axes[0, 1].bar(df_results['Algorithm'], df_results['Avg Reward'], color='lightgreen', edgecolor='black')\n",
    "axes[0, 1].set_ylabel('Average Reward', fontsize=11)\n",
    "axes[0, 1].set_title('Average Reward by Algorithm', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Validation Loss\n",
    "axes[1, 0].bar(df_results['Algorithm'], df_results['Val Loss'], color='salmon', edgecolor='black')\n",
    "axes[1, 0].set_ylabel('Validation Loss', fontsize=11)\n",
    "axes[1, 0].set_title('Validation Loss by Algorithm', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "axes[1, 0].set_yscale('log')\n",
    "\n",
    "# Training Time\n",
    "axes[1, 1].bar(df_results['Algorithm'], df_results['Train Time (s)'], color='plum', edgecolor='black')\n",
    "axes[1, 1].set_ylabel('Training Time (s)', fontsize=11)\n",
    "axes[1, 1].set_title('Training Time by Algorithm', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print best configuration details\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"BEST CONFIGURATION DETAILS\")\n",
    "print(\"=\"*100)\n",
    "for algo_name, results_list in grid_search_results.items():\n",
    "    best = results_list[0]\n",
    "    print(f\"\\n{algo_name}:\")\n",
    "    print(f\"  Config: {best['config']}\")\n",
    "    print(f\"  Val Loss: {best['final_val_loss']:.6f}\")\n",
    "    print(f\"  Training Time: {best['train_time']:.1f}s\")\n",
    "    print(f\"  Success Rate: {eval_results[algo_name]['success_rate']:.1%}\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf01ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best models\n",
    "import os\n",
    "save_dir = 'trained_models/grid_search_best'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for algo_name, results_list in grid_search_results.items():\n",
    "    best_result = results_list[0]\n",
    "    agent = best_result['agent']\n",
    "    \n",
    "    # Save model weights\n",
    "    model_path = os.path.join(save_dir, f'{algo_name}_best.pth')\n",
    "    \n",
    "    if hasattr(agent, 'model'):\n",
    "        torch.save(agent.model.state_dict(), model_path)\n",
    "    elif hasattr(agent, 'encoder') and hasattr(agent, 'decoder'):\n",
    "        torch.save({\n",
    "            'encoder': agent.encoder.state_dict(),\n",
    "            'decoder': agent.decoder.state_dict()\n",
    "        }, model_path)\n",
    "    \n",
    "    # Save config\n",
    "    config_path = os.path.join(save_dir, f'{algo_name}_config.pkl')\n",
    "    save_pickle({\n",
    "        'config': best_result['config'],\n",
    "        'val_loss': best_result['final_val_loss'],\n",
    "        'train_time': best_result['train_time'],\n",
    "        'eval_results': eval_results[algo_name]\n",
    "    }, config_path)\n",
    "    \n",
    "    print(f\"✓ Saved {algo_name} to {save_dir}\")\n",
    "\n",
    "print(f\"\\n✓ All best models saved to {save_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
