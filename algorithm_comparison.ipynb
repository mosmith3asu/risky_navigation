{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "578ac5ae",
   "metadata": {},
   "source": [
    "# Operator Action Prediction for Teleoperation with Communication Delays\n",
    "\n",
    "Comparing neural network architectures for predicting operator actions during communication delays in space teleoperation.\n",
    "\n",
    "## Problem\n",
    "\n",
    "Space teleoperation faces critical communication delays (Mars: 22 min, Moon: 1.25 sec). Operators cannot respond to obstacles in real-time.\n",
    "\n",
    "## Approach\n",
    "\n",
    "Learn models that predict operator actions based on current state, previous action, and goal position.\n",
    "\n",
    "## Algorithms\n",
    "\n",
    "1. **Linear** - Simple baseline\n",
    "2. **Bayesian** - Uncertainty-aware predictions\n",
    "3. **VAE** - Latent action distributions\n",
    "4. **Transformer** - Temporal sequence modeling\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. Expert demonstrations from visibility graph policy\n",
    "2. Train models with grid search\n",
    "3. Evaluate prediction accuracy and success rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7077109",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3f6497",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas matplotlib seaborn scikit-learn torch torchvision torchaudio gymnasium tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2cea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "print(os.path.abspath('.'))\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c632d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/risky_navigation')\n",
    "\n",
    "from src.env.continuous_nav_env import ContinuousNavigationEnv\n",
    "from src.env.layouts import read_layout_dict\n",
    "from src.algorithms.Bayesian.agent import BayesianAgent\n",
    "from src.algorithms.Transformer.agent import TransformerAgent\n",
    "from src.algorithms.Linear.agent import LinearAgent\n",
    "from src.algorithms.VAE.agent import VAEAgent\n",
    "from src.utils.file_management import save_pickle, load_pickle\n",
    "from src.utils.visibility_graph import VisibilityGraph\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device available: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57817ec8",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a17c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'num_episodes': 1000,\n",
    "    'max_steps': 200,\n",
    "    'batch_size': 512,  # Increased for RTX 4090\n",
    "    'num_epochs': 200,\n",
    "    'val_ratio': 0.2,\n",
    "    'num_test_episodes': 50,\n",
    "    'lr': 1e-3,\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'num_workers': 4,  # Parallel data loading\n",
    "    'prefetch_factor': 2,\n",
    "}\n",
    "\n",
    "# Grid search configurations for each algorithm\n",
    "GRID_SEARCH_CONFIGS = {\n",
    "    'Transformer': {\n",
    "        'd_model': [32, 64, 128],\n",
    "        'nhead': [4, 8],\n",
    "        'num_layers': [2, 3, 4],\n",
    "        'dropout': [0.0, 0.1, 0.2],\n",
    "        'sequence_len': [1, 5, 10],  # Added: temporal sequence length for time-series modeling\n",
    "        'lr': [1e-3, 5e-4, 1e-4]\n",
    "    },\n",
    "    'Bayesian': {\n",
    "        'hidden_dim': [64, 128, 256],\n",
    "        'prior_std': [0.5, 1.0, 2.0],\n",
    "        'kl_weight': [1e-5, 1e-4, 1e-3],  # Added: KL divergence weight for ELBO\n",
    "        'lr': [1e-3, 5e-4, 1e-4]\n",
    "    },\n",
    "    'VAE': {\n",
    "        'latent_dim': [16, 32, 64],\n",
    "        'hidden_dim': [64, 128, 256],\n",
    "        'beta': [0.5, 1.0, 2.0],\n",
    "        'lr': [1e-3, 5e-4, 1e-4]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Best baseline configs (for quick comparison)\n",
    "MODEL_CONFIGS = {\n",
    "    'Linear': {},\n",
    "    'Transformer': {'d_model': 64, 'nhead': 4, 'num_layers': 2, 'dropout': 0.1, 'sequence_len': 1},\n",
    "    'Bayesian': {'hidden_dim': 128, 'prior_std': 1.0, 'kl_weight': 1e-5},\n",
    "    'VAE': {'latent_dim': 32, 'hidden_dim': 128, 'beta': 1.0}\n",
    "}\n",
    "\n",
    "print(f\"Using device: {CONFIG['device']}\")\n",
    "print(f\"Batch size: {CONFIG['batch_size']} (optimized for RTX 4090)\")\n",
    "print(f\"Max epochs: {CONFIG['num_epochs']} (with early stopping)\")\n",
    "print(f\"Grid search enabled for: {list(GRID_SEARCH_CONFIGS.keys())}\")\n",
    "print(f\"\\nTransformer will test sequence lengths: {GRID_SEARCH_CONFIGS['Transformer']['sequence_len']}\")\n",
    "print(f\"  - sequence_len=1: Single state\")\n",
    "print(f\"  - sequence_len>1: Temporal sequences (time-series modeling)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # RTX 4090 optimizations\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "    \n",
    "    # Enable cuDNN autotuner for optimal convolution algorithms\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    \n",
    "    # Memory optimizations\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Mixed precision training setup\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    use_amp = True\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"GPU OPTIMIZATIONS ENABLED FOR RTX 4090\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"✓ Batch size: {CONFIG['batch_size']}\")\n",
    "    print(f\"✓ TF32 matmul: Enabled\")\n",
    "    print(f\"✓ cuDNN benchmark: Enabled\")\n",
    "    print(f\"✓ Mixed precision (AMP): Enabled\")\n",
    "    print(f\"✓ CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"✓ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"✓ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    use_amp = False\n",
    "    scaler = None\n",
    "    print(\"WARNING: CUDA not available. Running on CPU will be very slow!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39622191",
   "metadata": {},
   "source": [
    "## Training Functions with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2b379d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent_optimized(agent, train_states, train_prev_actions, train_expert_actions, train_goals,\n",
    "                          val_states, val_prev_actions, val_expert_actions, val_goals, \n",
    "                          num_epochs=50, batch_size=64, patience=10, verbose=True):\n",
    "    device = CONFIG['device']\n",
    "    use_amp = CONFIG['device'].type == 'cuda'\n",
    "    scaler = torch.cuda.amp.GradScaler() if use_amp else None\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(agent.optimizer, 'min', patience=5, factor=0.5)\n",
    "    train_losses, val_losses = [], []\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        indices = torch.randperm(len(train_states))\n",
    "        for i in range(0, len(train_states), batch_size):\n",
    "            batch_idx = indices[i:i+batch_size]\n",
    "            batch_states = torch.tensor(train_states[batch_idx], dtype=torch.float32, device=device)\n",
    "            batch_prev_actions = torch.tensor(train_prev_actions[batch_idx], dtype=torch.float32, device=device)\n",
    "            batch_actions = torch.tensor(train_expert_actions[batch_idx], dtype=torch.float32, device=device)\n",
    "            batch_goals = torch.tensor(train_goals[batch_idx], dtype=torch.float32, device=device)\n",
    "            \n",
    "            if use_amp and isinstance(agent, (BayesianAgent, VAEAgent)):\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    if hasattr(agent, 'model'):\n",
    "                        agent.model.train()\n",
    "                        agent.optimizer.zero_grad()\n",
    "                        inputs = torch.cat([batch_states, batch_prev_actions, batch_goals], dim=1)\n",
    "                        predictions = agent.model(inputs)\n",
    "                        loss = agent.loss_fn(predictions, batch_actions)\n",
    "                    elif hasattr(agent, 'encoder'):\n",
    "                        loss = torch.tensor(agent.train_step(batch_states, batch_prev_actions, batch_goals, batch_actions), device=device)\n",
    "                \n",
    "                if isinstance(loss, torch.Tensor) and loss.requires_grad:\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(agent.optimizer)\n",
    "                    scaler.update()\n",
    "                    scheduler.step()\n",
    "                    loss = loss.item()\n",
    "                else:\n",
    "                    scheduler.step()\n",
    "            else:\n",
    "                loss = agent.train_step(batch_states, batch_prev_actions, batch_goals, batch_actions)\n",
    "                if isinstance(loss, torch.Tensor):\n",
    "                    loss = loss.item()\n",
    "                scheduler.step()\n",
    "            \n",
    "            epoch_loss += loss\n",
    "            num_batches += 1\n",
    "        \n",
    "        avg_train_loss = epoch_loss / num_batches\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        val_states_t = torch.tensor(val_states, dtype=torch.float32, device=device)\n",
    "        val_prev_actions_t = torch.tensor(val_prev_actions, dtype=torch.float32, device=device)\n",
    "        val_actions_t = torch.tensor(val_expert_actions, dtype=torch.float32, device=device)\n",
    "        val_goals_t = torch.tensor(val_goals, dtype=torch.float32, device=device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if hasattr(agent, 'model'):\n",
    "                agent.model.eval()\n",
    "                inputs = torch.cat([val_states_t, val_prev_actions_t, val_goals_t], dim=1)\n",
    "                predictions = agent.model(inputs)\n",
    "                agent.model.train()\n",
    "            elif hasattr(agent, 'encoder'):\n",
    "                agent.encoder.eval()\n",
    "                agent.decoder.eval()\n",
    "                inputs = torch.cat([val_states_t, val_prev_actions_t, val_goals_t], dim=1)\n",
    "                mu, _ = agent.encoder(inputs)\n",
    "                predictions = agent.decoder(mu)\n",
    "                agent.encoder.train()\n",
    "                agent.decoder.train()\n",
    "            \n",
    "            val_loss = torch.nn.functional.mse_loss(predictions, val_actions_t).item()\n",
    "        \n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            if hasattr(agent, 'model'):\n",
    "                best_model_state = agent.model.state_dict()\n",
    "            elif hasattr(agent, 'encoder'):\n",
    "                best_model_state = {'encoder': agent.encoder.state_dict(), 'decoder': agent.decoder.state_dict()}\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                if verbose:\n",
    "                    print(f\"Early stop at epoch {epoch}. Best val: {best_val_loss:.6f}\")\n",
    "                if best_model_state:\n",
    "                    if hasattr(agent, 'model'):\n",
    "                        agent.model.load_state_dict(best_model_state)\n",
    "                    elif hasattr(agent, 'encoder'):\n",
    "                        agent.encoder.load_state_dict(best_model_state['encoder'])\n",
    "                        agent.decoder.load_state_dict(best_model_state['decoder'])\n",
    "                break\n",
    "        \n",
    "        if verbose and epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}: Train={avg_train_loss:.6f}, Val={val_loss:.6f}\")\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "print(\"Training function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d212700",
   "metadata": {},
   "outputs": [],
   "source": [
    "for alg_name, (AgentClass, param_grid) in algorithms_with_grid.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Grid Search: {alg_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    param_names = list(param_grid.keys())\n",
    "    param_values = list(param_grid.values())\n",
    "    \n",
    "    from itertools import product\n",
    "    configs = list(product(*param_values))\n",
    "    total_configs = len(configs)\n",
    "    \n",
    "    print(f\"Testing {total_configs} configurations for {alg_name}...\")\n",
    "    \n",
    "    best_config = None\n",
    "    best_val_loss = float('inf')\n",
    "    best_agent = None\n",
    "    best_train_time = 0\n",
    "    \n",
    "    for config_idx, config_vals in enumerate(configs):\n",
    "        config = dict(zip(param_names, config_vals))\n",
    "        \n",
    "        print(f\"  [{config_idx+1}/{total_configs}] Testing {config}...\")\n",
    "        \n",
    "        try:\n",
    "            agent = AgentClass(\n",
    "                state_dim=STATE_DIM,\n",
    "                action_dim=ACTION_DIM,\n",
    "                goal_dim=GOAL_DIM,\n",
    "                **config,\n",
    "                device=CONFIG['device']\n",
    "            )\n",
    "            \n",
    "            start_time = time.time()\n",
    "            train_losses, val_losses = train_agent_optimized(\n",
    "                agent,\n",
    "                train_states, train_prev_actions, train_actions, train_goals,\n",
    "                val_states, val_prev_actions, val_actions, val_goals,\n",
    "                num_epochs=CONFIG['num_epochs'],\n",
    "                batch_size=CONFIG['batch_size'],\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "            val_loss = min(val_losses) if val_losses else float('inf')\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_config = config\n",
    "                best_agent = agent\n",
    "                best_train_time = elapsed_time\n",
    "                print(f\"    ✓ New best: {val_loss:.6f}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"    ✗ Failed: {e}\")\n",
    "            continue\n",
    "    \n",
    "    grid_search_results[alg_name] = {\n",
    "        'best_config': best_config,\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'best_agent': best_agent,\n",
    "        'train_time': best_train_time\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{alg_name} Best Config: {best_config}\")\n",
    "    print(f\"{alg_name} Best Val Loss: {best_val_loss:.6f}\")\n",
    "    print(f\"{alg_name} Train Time: {best_train_time:.2f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GRID SEARCH COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "for alg_name, result in grid_search_results.items():\n",
    "    print(f\"{alg_name:12} | Val Loss: {result['best_val_loss']:.6f} | Time: {result['train_time']:.2f}s\")\n",
    "    print(f\"             | Config: {result['best_config']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1652df29",
   "metadata": {},
   "source": [
    "## Data Collection and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7f97ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_rl_experience(env, vgraph, num_episodes=100, max_steps=200):\n",
    "    data = []\n",
    "    successful_episodes = 0\n",
    "    \n",
    "    for ep in tqdm(range(num_episodes), desc='Collecting experience'):\n",
    "        state = env.reset()\n",
    "        goal = env.goal.copy()\n",
    "        prev_action = np.zeros(2)\n",
    "        \n",
    "        for t in range(max_steps):\n",
    "            current_pos = state[:2]\n",
    "            current_theta = state[2]\n",
    "            \n",
    "            _, path = vgraph(current_pos)\n",
    "            if len(path) > 1:\n",
    "                target = np.array(path[1])\n",
    "            else:\n",
    "                target = goal\n",
    "            \n",
    "            direction = target - current_pos\n",
    "            desired_theta = np.arctan2(direction[1], direction[0])\n",
    "            angle_diff = desired_theta - current_theta\n",
    "            angle_diff = (angle_diff + np.pi) % (2 * np.pi) - np.pi\n",
    "            \n",
    "            steering = np.clip(angle_diff * 2.0, env.action_space.low[1], env.action_space.high[1])\n",
    "            dist_to_target = np.linalg.norm(direction)\n",
    "            \n",
    "            if dist_to_target < env.goal_radius * 3:\n",
    "                throttle = env.action_space.high[0] * 0.3\n",
    "            else:\n",
    "                throttle = env.action_space.high[0] * 0.8\n",
    "            \n",
    "            action = np.array([throttle, steering])\n",
    "            action = np.clip(action, env.action_space.low, env.action_space.high)\n",
    "            \n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            data.append({\n",
    "                'state': state.copy(),\n",
    "                'prev_action': prev_action.copy(),\n",
    "                'action': action.copy(),\n",
    "                'goal': goal.copy()\n",
    "            })\n",
    "            \n",
    "            prev_action = action\n",
    "            state = next_state\n",
    "            \n",
    "            if done:\n",
    "                if info.get('reason') == 'goal_reached':\n",
    "                    successful_episodes += 1\n",
    "                break\n",
    "    \n",
    "    print(f\"Collected {len(data)} transitions from {num_episodes} episodes\")\n",
    "    print(f\"Success rate: {successful_episodes/num_episodes:.2%}\")\n",
    "    return data\n",
    "\n",
    "print(\"Data collection function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a347d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'expert_dataset.pickle'\n",
    "\n",
    "if os.path.exists(dataset_path):\n",
    "    print(f\"Loading existing dataset from {dataset_path}...\")\n",
    "    data = load_pickle(dataset_path)\n",
    "    print(f\"✓ Loaded {len(data)} transitions\")\n",
    "else:\n",
    "    print(f\"Collecting new dataset...\")\n",
    "    layout_dict = read_layout_dict('example0')\n",
    "    env_collect = ContinuousNavigationEnv(**layout_dict)\n",
    "    vgraph = VisibilityGraph(env_collect.goal, env_collect.obstacles, env_collect.bounds, resolution=(20, 20))\n",
    "    data = collect_rl_experience(env_collect, vgraph, num_episodes=CONFIG['num_episodes'], max_steps=CONFIG['max_steps'])\n",
    "    save_pickle(data, dataset_path)\n",
    "    print(f\"✓ Saved dataset to {dataset_path}\")\n",
    "\n",
    "states = np.array([d['state'] for d in data])\n",
    "prev_actions = np.array([d['prev_action'] for d in data])\n",
    "actions = np.array([d['action'] for d in data])\n",
    "goals = np.array([d['goal'] for d in data])\n",
    "\n",
    "print(f\"\\nDataset Summary:\")\n",
    "print(f\"  Total transitions: {len(data)}\")\n",
    "print(f\"  States shape: {states.shape}\")\n",
    "print(f\"  Prev actions shape: {prev_actions.shape}\")\n",
    "print(f\"  Actions shape: {actions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437071f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_DIM = states.shape[1]\n",
    "ACTION_DIM = actions.shape[1]\n",
    "layout_dict = read_layout_dict('example0')\n",
    "env = ContinuousNavigationEnv(**layout_dict)\n",
    "\n",
    "print(f\"Environment & Data Configuration:\")\n",
    "print(f\"  STATE_DIM = {STATE_DIM}\")\n",
    "print(f\"  ACTION_DIM = {ACTION_DIM}\")\n",
    "print(f\"  Total samples = {len(states)}\")\n",
    "print(f\"  State space: {env.observation_space.shape}\")\n",
    "print(f\"  Action space: {env.action_space.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d49cc82",
   "metadata": {},
   "source": [
    "## Grid Search Training - All Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9da6b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"GRID SEARCH TRAINING - ALL ALGORITHMS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "GOAL_DIM = 2\n",
    "n_samples = len(states)\n",
    "n_train = int(n_samples * (1 - CONFIG['val_ratio']))\n",
    "indices = np.random.permutation(n_samples)\n",
    "train_indices = indices[:n_train]\n",
    "val_indices = indices[n_train:]\n",
    "\n",
    "train_states = states[train_indices]\n",
    "train_prev_actions = prev_actions[train_indices]\n",
    "train_actions = actions[train_indices]\n",
    "train_goals = goals[train_indices]\n",
    "\n",
    "val_states = states[val_indices]\n",
    "val_prev_actions = prev_actions[val_indices]\n",
    "val_actions = actions[val_indices]\n",
    "val_goals = goals[val_indices]\n",
    "\n",
    "print(f\"Data split: {len(train_states)} train, {len(val_states)} val\")\n",
    "print(f\"Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"Max epochs: {CONFIG['num_epochs']}\\n\")\n",
    "\n",
    "grid_search_results = {}\n",
    "algorithms_with_grid = {\n",
    "    'Transformer': (TransformerAgent, GRID_SEARCH_CONFIGS['Transformer']),\n",
    "    'Bayesian': (BayesianAgent, GRID_SEARCH_CONFIGS['Bayesian']),\n",
    "    'VAE': (VAEAgent, GRID_SEARCH_CONFIGS['VAE'])\n",
    "}\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training Linear (Baseline - No Grid Search)\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "linear_agent = LinearAgent(\n",
    "    state_dim=STATE_DIM,\n",
    "    action_dim=ACTION_DIM,\n",
    "    goal_dim=GOAL_DIM,\n",
    "    lr=CONFIG['lr'],\n",
    "    device=CONFIG['device'],\n",
    "    action_low=env.action_space.low,\n",
    "    action_high=env.action_space.high\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "train_losses, val_losses = train_agent_optimized(\n",
    "    linear_agent,\n",
    "    train_states, train_prev_actions, train_actions, train_goals,\n",
    "    val_states, val_prev_actions, val_actions, val_goals,\n",
    "    num_epochs=CONFIG['num_epochs'],\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "best_val_loss = min(val_losses) if val_losses else float('inf')\n",
    "\n",
    "print(f\"Linear - Train time: {elapsed_time:.2f}s, Best val loss: {best_val_loss:.6f}\")\n",
    "\n",
    "grid_search_results['Linear'] = {\n",
    "    'best_config': {'lr': CONFIG['lr']},\n",
    "    'best_val_loss': best_val_loss,\n",
    "    'best_agent': linear_agent,\n",
    "    'train_time': elapsed_time\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcf49a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search Results Visualization\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VISUALIZING GRID SEARCH RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Figure 1: Training and Validation Curves for Top 5 Configs per Algorithm\n",
    "fig1, axes1 = plt.subplots(len(grid_search_results), 2, figsize=(18, 4*len(grid_search_results)))\n",
    "if len(grid_search_results) == 1:\n",
    "    axes1 = axes1.reshape(1, -1)\n",
    "\n",
    "for idx, (algo_name, results_list) in enumerate(grid_search_results.items()):\n",
    "    ax_train = axes1[idx, 0]\n",
    "    ax_val = axes1[idx, 1]\n",
    "    \n",
    "    # Plot top 5 configs\n",
    "    for i, result in enumerate(results_list[:5]):\n",
    "        epochs = range(len(result['train_losses']))\n",
    "        \n",
    "        # Config label with key parameters\n",
    "        if result['config']:\n",
    "            key_params = {k: v for k, v in result['config'].items() if k in ['lr', 'latent_dim', 'd_model', 'hidden_dim']}\n",
    "            config_label = f\"Rank {i+1}: \" + \", \".join([f\"{k}={v}\" for k, v in key_params.items()])\n",
    "        else:\n",
    "            config_label = \"Baseline\"\n",
    "        \n",
    "        ax_train.plot(epochs, result['train_losses'], label=config_label, alpha=0.8, linewidth=2)\n",
    "        ax_val.plot(epochs, result['val_losses'], label=config_label, alpha=0.8, linewidth=2)\n",
    "    \n",
    "    # Configure plots\n",
    "    ax_train.set_xlabel('Epoch', fontsize=11)\n",
    "    ax_train.set_ylabel('Training Loss', fontsize=11)\n",
    "    ax_train.set_title(f'{algo_name} - Training Loss (Top 5 Configs)', fontsize=12, fontweight='bold')\n",
    "    ax_train.legend(fontsize=9, loc='best')\n",
    "    ax_train.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax_train.set_yscale('log')\n",
    "    \n",
    "    ax_val.set_xlabel('Epoch', fontsize=11)\n",
    "    ax_val.set_ylabel('Validation Loss', fontsize=11)\n",
    "    ax_val.set_title(f'{algo_name} - Validation Loss (Top 5 Configs)', fontsize=12, fontweight='bold')\n",
    "    ax_val.legend(fontsize=9, loc='best')\n",
    "    ax_val.grid(True, alpha=0.3, linestyle='--')\n",
    "    ax_val.set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Figure 2: Performance Comparison - Val Loss vs Training Time\n",
    "fig2, ax2 = plt.subplots(1, 1, figsize=(14, 8))\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(grid_search_results)))\n",
    "markers = ['o', 's', '^', 'D']\n",
    "\n",
    "for idx, (algo_name, results_list) in enumerate(grid_search_results.items()):\n",
    "    val_losses = [r['final_val_loss'] for r in results_list[:10]]\n",
    "    train_times = [r['train_time'] for r in results_list[:10]]\n",
    "    \n",
    "    ax2.scatter(train_times, val_losses, s=200, alpha=0.6, \n",
    "               color=colors[idx], marker=markers[idx % len(markers)],\n",
    "               label=algo_name, edgecolors='black', linewidth=1.5)\n",
    "    \n",
    "    # Annotate best config\n",
    "    ax2.annotate(f'{algo_name}\\nBest', \n",
    "                xy=(train_times[0], val_losses[0]),\n",
    "                xytext=(10, 10), textcoords='offset points',\n",
    "                fontsize=9, fontweight='bold',\n",
    "                bbox=dict(boxstyle='round,pad=0.5', facecolor=colors[idx], alpha=0.3),\n",
    "                arrowprops=dict(arrowstyle='->', lw=1.5))\n",
    "\n",
    "ax2.set_xlabel('Training Time (seconds)', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Final Validation Loss', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Grid Search: Validation Loss vs Training Time', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=10, loc='best', framealpha=0.9)\n",
    "ax2.grid(True, alpha=0.3, linestyle='--')\n",
    "ax2.set_yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary tables\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"GRID SEARCH RESULTS - TOP 5 CONFIGS PER ALGORITHM\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "for algo_name, results_list in grid_search_results.items():\n",
    "    print(f\"\\n{algo_name}:\")\n",
    "    print(f\"{'Rank':<6} {'Val Loss':<12} {'Train Loss':<12} {'Time(s)':<10} {'Epochs':<8} {'Config'}\")\n",
    "    print(\"-\" * 120)\n",
    "    \n",
    "    for rank, result in enumerate(results_list[:5], 1):\n",
    "        config_str = ', '.join([f\"{k}={v}\" for k, v in result['config'].items()]) or \"N/A (baseline)\"\n",
    "        final_train_loss = result['train_losses'][-1]\n",
    "        num_epochs = len(result['train_losses'])\n",
    "        \n",
    "        print(f\"{rank:<6} {result['final_val_loss']:<12.6f} {final_train_loss:<12.6f} \"\n",
    "              f\"{result['train_time']:<10.1f} {num_epochs:<8} {config_str}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*120)\n",
    "print(f\"{'Algorithm':<15} {'Configs':<10} {'Best Val':<12} {'Worst Val':<12} {'Avg Val':<12} {'Std Val':<12}\")\n",
    "print(\"-\" * 120)\n",
    "\n",
    "for algo_name, results_list in grid_search_results.items():\n",
    "    val_losses = [r['final_val_loss'] for r in results_list]\n",
    "    print(f\"{algo_name:<15} {len(results_list):<10} {min(val_losses):<12.6f} \"\n",
    "          f\"{max(val_losses):<12.6f} {np.mean(val_losses):<12.6f} {np.std(val_losses):<12.6f}\")\n",
    "\n",
    "print(\"=\"*120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507cee6b",
   "metadata": {},
   "source": [
    "## Evaluate Best Models from Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dfdccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EVALUATING BEST MODELS FROM GRID SEARCH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def evaluate_agent_optimized(agent, env, num_episodes=50, max_steps=200, device='cpu'):\n",
    "    results = {\n",
    "        'rewards': [], \n",
    "        'successes': [], \n",
    "        'steps': [],\n",
    "        'final_distances': [],\n",
    "        'final_velocities': []\n",
    "    }\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        goal = env.goal.copy() if hasattr(env, 'goal') else np.zeros(2)\n",
    "        prev_action = np.zeros(ACTION_DIM)\n",
    "        episode_reward = 0\n",
    "        done = False\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            state_t = torch.tensor(state, dtype=torch.float32, device=device)\n",
    "            prev_action_t = torch.tensor(prev_action, dtype=torch.float32, device=device)\n",
    "            goal_t = torch.tensor(goal, dtype=torch.float32, device=device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                action = agent.predict_action(state_t, prev_action_t, goal_t)\n",
    "            \n",
    "            if isinstance(action, torch.Tensor):\n",
    "                action = action.cpu().numpy()\n",
    "            \n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            episode_reward += reward\n",
    "            prev_action = action\n",
    "            state = next_state\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        results['rewards'].append(episode_reward)\n",
    "        success = info.get('reason', '') == 'goal_reached' if done else False\n",
    "        results['successes'].append(1 if success else 0)\n",
    "        results['steps'].append(step + 1)\n",
    "        results['final_distances'].append(np.linalg.norm(state[:2] - goal))\n",
    "        results['final_velocities'].append(state[3])\n",
    "    \n",
    "    return {\n",
    "        'avg_reward': np.mean(results['rewards']),\n",
    "        'success_rate': np.mean(results['successes']),\n",
    "        'avg_steps': np.mean(results['steps']),\n",
    "        'avg_final_dist': np.mean(results['final_distances']),\n",
    "        'avg_final_vel': np.mean(results['final_velocities'])\n",
    "    }\n",
    "\n",
    "eval_results = {}\n",
    "env_eval = ContinuousNavigationEnv()\n",
    "\n",
    "for alg_name, result in grid_search_results.items():\n",
    "    agent = result['best_agent']\n",
    "    print(f\"\\nEvaluating {alg_name}...\")\n",
    "    eval_res = evaluate_agent_optimized(agent, env_eval, num_episodes=CONFIG['num_test_episodes'], device=CONFIG['device'])\n",
    "    eval_results[alg_name] = eval_res\n",
    "    print(f\"{alg_name} - Success: {eval_res['success_rate']:.1%}, Avg Reward: {eval_res['avg_reward']:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3cc541",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_data = []\n",
    "for alg_name, result in grid_search_results.items():\n",
    "    eval_res = eval_results[alg_name]\n",
    "    results_data.append({\n",
    "        'Algorithm': alg_name,\n",
    "        'Val Loss': result['best_val_loss'],\n",
    "        'Train Time (s)': result['train_time'],\n",
    "        'Success Rate': eval_res['success_rate'],\n",
    "        'Avg Reward': eval_res['avg_reward'],\n",
    "        'Avg Steps': eval_res['avg_steps'],\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results_data)\n",
    "df_results = df_results.sort_values('Val Loss')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(df_results.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "axes[0, 0].bar(df_results['Algorithm'], df_results['Success Rate'], color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_ylabel('Success Rate')\n",
    "axes[0, 0].set_title('Success Rate by Algorithm')\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "axes[0, 0].set_ylim([0, 1.1])\n",
    "\n",
    "axes[0, 1].bar(df_results['Algorithm'], df_results['Avg Reward'], color='lightgreen', edgecolor='black')\n",
    "axes[0, 1].set_ylabel('Average Reward')\n",
    "axes[0, 1].set_title('Average Reward by Algorithm')\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "axes[1, 0].bar(df_results['Algorithm'], df_results['Val Loss'], color='salmon', edgecolor='black')\n",
    "axes[1, 0].set_ylabel('Validation Loss')\n",
    "axes[1, 0].set_title('Validation Loss by Algorithm')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "axes[1, 0].set_yscale('log')\n",
    "\n",
    "axes[1, 1].bar(df_results['Algorithm'], df_results['Train Time (s)'], color='plum', edgecolor='black')\n",
    "axes[1, 1].set_ylabel('Training Time (s)')\n",
    "axes[1, 1].set_title('Training Time by Algorithm')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf01ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'trained_models/grid_search_best'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for alg_name, result in grid_search_results.items():\n",
    "    agent = result['best_agent']\n",
    "    model_path = os.path.join(save_dir, f'{alg_name}_best.pth')\n",
    "    \n",
    "    if hasattr(agent, 'model'):\n",
    "        torch.save(agent.model.state_dict(), model_path)\n",
    "    elif hasattr(agent, 'encoder'):\n",
    "        torch.save({'encoder': agent.encoder.state_dict(), 'decoder': agent.decoder.state_dict()}, model_path)\n",
    "    \n",
    "    config_path = os.path.join(save_dir, f'{alg_name}_config.pkl')\n",
    "    save_pickle({\n",
    "        'config': result['best_config'],\n",
    "        'val_loss': result['best_val_loss'],\n",
    "        'train_time': result['train_time'],\n",
    "        'eval_results': eval_results[alg_name]\n",
    "    }, config_path)\n",
    "\n",
    "print(f\"Models and configs saved to {save_dir}/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
