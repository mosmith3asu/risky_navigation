{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "578ac5ae",
   "metadata": {},
   "source": [
    "# Operator Action Prediction for Teleoperation with Communication Delays\n",
    "\n",
    "Comparing neural network architectures for predicting operator actions during communication delays in space teleoperation.\n",
    "\n",
    "## Problem\n",
    "\n",
    "Space teleoperation faces critical communication delays (Mars: 22 min, Moon: 1.25 sec). Operators cannot respond to obstacles in real-time.\n",
    "\n",
    "## Approach\n",
    "\n",
    "Learn models that predict operator actions based on current state, previous action, and goal position.\n",
    "\n",
    "## Algorithms\n",
    "\n",
    "1. **Linear** - Simple baseline\n",
    "2. **Bayesian** - Uncertainty-aware predictions\n",
    "3. **VAE** - Latent action distributions\n",
    "4. **Transformer** - Temporal sequence modeling\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. Expert demonstrations from visibility graph policy\n",
    "2. Train models with **random search** (more efficient than grid search)\n",
    "3. Evaluate prediction accuracy and success rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7077109",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec3f6497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.8-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.8.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.4.1+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.19.1+cu124)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.4.1+cu124)\n",
      "Collecting gymnasium\n",
      "  Downloading gymnasium-1.2.3-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting shapely\n",
      "  Downloading shapely-2.1.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting numba\n",
      "  Downloading numba-0.63.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.61.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (10.2.0)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting scipy>=1.10.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Collecting joblib>=1.3.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.2.65 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.2.65)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.0.44 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.0.44)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.119 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.119)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.0.99 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.0.99)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.0.142 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.0.142)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.99)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.99 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.99)\n",
      "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.0.0)\n",
      "Collecting cloudpickle>=1.2.0 (from gymnasium)\n",
      "  Downloading cloudpickle-3.1.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Collecting llvmlite<0.47,>=0.46.0dev0 (from numba)\n",
      "  Downloading llvmlite-0.46.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch) (1.3.0)\n",
      "Downloading pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.8-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m335.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading scikit_learn-1.8.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (9.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m358.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gymnasium-1.2.3-py3-none-any.whl (952 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.1/952.1 kB\u001b[0m \u001b[31m250.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading shapely-2.1.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m330.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.63.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m235.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-3.1.2-py3-none-any.whl (22 kB)\n",
      "Downloading contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (355 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Downloading fonttools-4.61.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m284.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Downloading kiwisolver-1.4.9-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m198.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.46.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m287.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.3.1-py3-none-any.whl (121 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading scipy-1.16.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m257.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "Installing collected packages: pytz, farama-notifications, tzdata, tqdm, threadpoolctl, shapely, scipy, pyparsing, llvmlite, kiwisolver, joblib, fonttools, cycler, contourpy, cloudpickle, scikit-learn, pandas, numba, matplotlib, gymnasium, seaborn\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 2.4.7\n",
      "    Uninstalling pyparsing-2.4.7:\n",
      "      Successfully uninstalled pyparsing-2.4.7\n",
      "Successfully installed cloudpickle-3.1.2 contourpy-1.3.3 cycler-0.12.1 farama-notifications-0.0.4 fonttools-4.61.1 gymnasium-1.2.3 joblib-1.5.3 kiwisolver-1.4.9 llvmlite-0.46.0 matplotlib-3.10.8 numba-0.63.1 pandas-2.3.3 pyparsing-3.3.1 pytz-2025.2 scikit-learn-1.8.0 scipy-1.16.3 seaborn-0.13.2 shapely-2.1.2 threadpoolctl-3.6.0 tqdm-4.67.1 tzdata-2025.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas matplotlib seaborn scikit-learn torch torchvision torchaudio gymnasium tqdm shapely numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d615b217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'risky_navigation'...\n",
      "remote: Enumerating objects: 814, done.\u001b[K\n",
      "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
      "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
      "remote: Total 814 (delta 10), reused 14 (delta 5), pack-reused 790 (from 1)\u001b[K\n",
      "Receiving objects: 100% (814/814), 19.91 MiB | 16.31 MiB/s, done.\n",
      "Resolving deltas: 100% (450/450), done.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf risky_navigation\n",
    "!git clone https://github.com/mosmith3asu/risky_navigation.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93444736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGC-DL-CONTAINER-LICENSE    get-pip.py\t libx32\t\t   root      tmp\n",
      "bin\t\t\t    home\t media\t\t   run\t     usr\n",
      "boot\t\t\t    jupyter.log  mnt\t\t   sbin      var\n",
      "cuda-keyring_1.1-1_all.deb  lib\t\t opt\t\t   srv\t     workspace\n",
      "dev\t\t\t    lib32\t proc\t\t   start.sh\n",
      "etc\t\t\t    lib64\t risky_navigation  sys\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe2cea94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "print(os.path.abspath('.'))\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c632d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n",
      "PyTorch version: 2.4.1+cu124\n",
      "Device available: CUDA\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./risky_navigation')\n",
    "\n",
    "from src.env.continuous_nav_env import ContinuousNavigationEnv\n",
    "from src.env.layouts import read_layout_dict\n",
    "from src.algorithms.Bayesian.agent import BayesianAgent\n",
    "from src.algorithms.Transformer.agent import TransformerAgent\n",
    "from src.algorithms.Linear.agent import LinearAgent\n",
    "from src.algorithms.VAE.agent import VAEAgent\n",
    "from src.utils.file_management import save_pickle, load_pickle\n",
    "from src.utils.visibility_graph import VisibilityGraph\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device available: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57817ec8",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69a17c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Batch size: 512 (optimized for RTX 4090)\n",
      "Max epochs: 200 (with early stopping)\n",
      "Random search enabled for: ['Transformer', 'Bayesian', 'VAE', 'Linear']\n",
      "Trials per algorithm: 50\n",
      "Total configurations to test: 200\n",
      "\n",
      "All algorithms will test sequence lengths: [1, 5, 10]\n",
      "  - sequence_len=1: Single previous action (baseline)\n",
      "  - sequence_len>1: Temporal sequences (history-based prediction)\n"
     ]
    }
   ],
   "source": [
    "CONFIG = {\n",
    "    'num_episodes': 1000,\n",
    "    'max_steps': 200,\n",
    "    'batch_size': 512,  # Increased for RTX 4090\n",
    "    'num_epochs': 200,\n",
    "    'val_ratio': 0.2,\n",
    "    'num_test_episodes': 50,\n",
    "    'lr': 1e-3,\n",
    "    'device': torch.device('cuda'),\n",
    "    'num_workers': 4,  # Parallel data loading\n",
    "    'prefetch_factor': 2,\n",
    "    'n_random_trials': 50,  # Number of random configurations to test per algorithm\n",
    "}\n",
    "\n",
    "# Random search configurations for each algorithm (define ranges, not discrete values)\n",
    "RANDOM_SEARCH_CONFIGS = {\n",
    "    'Transformer': {\n",
    "        'd_model': (32, 128),  # (min, max)\n",
    "        'nhead': [4, 8],  # Discrete choices (must be divisors of d_model)\n",
    "        'num_layers': (2, 4),  # (min, max)\n",
    "        'dropout': (0.0, 0.2),  # (min, max)\n",
    "        'sequence_len': [1, 5, 10],  # Discrete choices\n",
    "        'lr': (1e-4, 1e-3),  # (min, max) log scale\n",
    "    },\n",
    "    'Bayesian': {\n",
    "        'hidden_dim': (64, 256),  # (min, max)\n",
    "        'prior_std': (0.5, 2.0),  # (min, max)\n",
    "        'kl_weight': (1e-5, 1e-3),  # (min, max) log scale\n",
    "        'sequence_len': [1, 5, 10],  # Discrete choices\n",
    "        'lr': (1e-4, 1e-3),  # (min, max) log scale\n",
    "    },\n",
    "    'VAE': {\n",
    "        'latent_dim': (16, 64),  # (min, max)\n",
    "        'hidden_dim': (64, 256),  # (min, max)\n",
    "        'beta': (0.5, 2.0),  # (min, max)\n",
    "        'sequence_len': [1, 5, 10],  # Discrete choices\n",
    "        'lr': (1e-4, 1e-3),  # (min, max) log scale\n",
    "    },\n",
    "    'Linear': {\n",
    "        'sequence_len': [1, 5, 10],  # Discrete choices\n",
    "        'lr': (1e-4, 1e-3),  # (min, max) log scale\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Using device: {CONFIG['device']}\")\n",
    "print(f\"Batch size: {CONFIG['batch_size']} (optimized for RTX 4090)\")\n",
    "print(f\"Max epochs: {CONFIG['num_epochs']} (with early stopping)\")\n",
    "print(f\"Random search enabled for: {list(RANDOM_SEARCH_CONFIGS.keys())}\")\n",
    "print(f\"Trials per algorithm: {CONFIG['n_random_trials']}\")\n",
    "print(f\"Total configurations to test: {CONFIG['n_random_trials'] * len(RANDOM_SEARCH_CONFIGS)}\")\n",
    "print(f\"\\nAll algorithms will test sequence lengths: {RANDOM_SEARCH_CONFIGS['Linear']['sequence_len']}\")\n",
    "print(f\"  - sequence_len=1: Single previous action (baseline)\")\n",
    "print(f\"  - sequence_len>1: Temporal sequences (history-based prediction)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a55f165b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GPU OPTIMIZATIONS ENABLED FOR RTX 4090\n",
      "============================================================\n",
      "✓ Batch size: 512\n",
      "✓ TF32 matmul: Enabled\n",
      "✓ cuDNN benchmark: Enabled\n",
      "✓ Mixed precision (AMP): Enabled\n",
      "✓ CUDA version: 12.4\n",
      "✓ GPU: NVIDIA GeForce RTX 4090\n",
      "✓ VRAM: 23.5 GB\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # RTX 4090 optimizations\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "    \n",
    "    # Enable cuDNN autotuner for optimal convolution algorithms\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    \n",
    "    # Memory optimizations\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Mixed precision training setup\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    use_amp = True\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"GPU OPTIMIZATIONS ENABLED FOR RTX 4090\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"✓ Batch size: {CONFIG['batch_size']}\")\n",
    "    print(f\"✓ TF32 matmul: Enabled\")\n",
    "    print(f\"✓ cuDNN benchmark: Enabled\")\n",
    "    print(f\"✓ Mixed precision (AMP): Enabled\")\n",
    "    print(f\"✓ CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"✓ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"✓ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    use_amp = False\n",
    "    scaler = None\n",
    "    print(\"WARNING: CUDA not available. Running on CPU will be very slow!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39622191",
   "metadata": {},
   "source": [
    "## Training Functions with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a2b379d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training function defined!\n"
     ]
    }
   ],
   "source": [
    "def train_agent_optimized(agent, train_state_seqs, train_action_seqs, train_target_actions, train_goals,\n",
    "                          val_state_seqs, val_action_seqs, val_target_actions, val_goals, \n",
    "                          num_epochs=50, batch_size=64, patience=10, verbose=True):\n",
    "    \"\"\"\n",
    "    Clean training function without fallback mechanisms.\n",
    "    All agents must implement train_step() and predict_action() methods.\n",
    "    \"\"\"\n",
    "    device = CONFIG['device']\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(agent.optimizer, 'min', patience=5, factor=0.5)\n",
    "    train_losses, val_losses = [], []\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        indices = torch.randperm(len(train_state_seqs))\n",
    "        for i in range(0, len(train_state_seqs), batch_size):\n",
    "            batch_idx = indices[i:i+batch_size]\n",
    "            batch_state_seqs = torch.tensor(train_state_seqs[batch_idx], dtype=torch.float32, device=device)\n",
    "            batch_action_seqs = torch.tensor(train_action_seqs[batch_idx], dtype=torch.float32, device=device)\n",
    "            batch_target_actions = torch.tensor(train_target_actions[batch_idx], dtype=torch.float32, device=device)\n",
    "            batch_goals = torch.tensor(train_goals[batch_idx], dtype=torch.float32, device=device)\n",
    "            \n",
    "            loss = agent.train_step(batch_state_seqs, batch_action_seqs, batch_goals, batch_target_actions)\n",
    "            if isinstance(loss, torch.Tensor):\n",
    "                loss = loss.item()\n",
    "            \n",
    "            epoch_loss += loss\n",
    "            num_batches += 1\n",
    "        \n",
    "        avg_train_loss = epoch_loss / num_batches\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validation phase - use agent's predict_action method\n",
    "        val_state_seqs_t = torch.tensor(val_state_seqs, dtype=torch.float32, device=device)\n",
    "        val_action_seqs_t = torch.tensor(val_action_seqs, dtype=torch.float32, device=device)\n",
    "        val_target_actions_t = torch.tensor(val_target_actions, dtype=torch.float32, device=device)\n",
    "        val_goals_t = torch.tensor(val_goals, dtype=torch.float32, device=device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Use agent's predict_action method (all agents implement this)\n",
    "            predictions = agent.predict_action(val_state_seqs_t, val_action_seqs_t, val_goals_t)\n",
    "            val_loss = torch.nn.functional.mse_loss(predictions, val_target_actions_t).item()\n",
    "        \n",
    "        val_losses.append(val_loss)\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Early stopping with model checkpointing\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            # Save best model state\n",
    "            agent.save(f'temp_best_model.pth')\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                if verbose:\n",
    "                    print(f\"Early stop at epoch {epoch}. Best val: {best_val_loss:.6f}\")\n",
    "                # Load best model\n",
    "                agent.load(f'temp_best_model.pth')\n",
    "                break\n",
    "        \n",
    "        if verbose and epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}: Train={avg_train_loss:.6f}, Val={val_loss:.6f}\")\n",
    "    \n",
    "    # Clean up temp file\n",
    "    import os\n",
    "    if os.path.exists('temp_best_model.pth'):\n",
    "        os.remove('temp_best_model.pth')\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "\n",
    "print(\"Training function defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a139911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random search sampling function defined!\n"
     ]
    }
   ],
   "source": [
    "def sample_random_config(param_ranges):\n",
    "    \"\"\"\n",
    "    Sample a random configuration from parameter ranges.\n",
    "    \n",
    "    Args:\n",
    "        param_ranges: Dict with parameter names as keys and ranges as values\n",
    "                     - Tuple (min, max): Continuous range (uniform sampling)\n",
    "                     - List: Discrete choices (random choice)\n",
    "                     \n",
    "    Returns:\n",
    "        Dict with sampled parameter values\n",
    "    \"\"\"\n",
    "    config = {}\n",
    "    for param_name, param_range in param_ranges.items():\n",
    "        if isinstance(param_range, tuple):\n",
    "            min_val, max_val = param_range\n",
    "            \n",
    "            # Log-scale sampling for learning rate and KL weight\n",
    "            if param_name in ['lr', 'kl_weight']:\n",
    "                log_min, log_max = np.log10(min_val), np.log10(max_val)\n",
    "                config[param_name] = 10 ** np.random.uniform(log_min, log_max)\n",
    "            # Integer sampling for discrete parameters\n",
    "            elif param_name in ['d_model', 'hidden_dim', 'latent_dim', 'num_layers']:\n",
    "                config[param_name] = np.random.randint(min_val, max_val + 1)\n",
    "                # Ensure d_model is divisible by nhead if needed\n",
    "                if param_name == 'd_model' and 'nhead' in param_ranges:\n",
    "                    nhead = np.random.choice(param_ranges['nhead'])\n",
    "                    config[param_name] = (config[param_name] // nhead) * nhead\n",
    "                    config[param_name] = max(config[param_name], min_val)\n",
    "            # Continuous sampling\n",
    "            else:\n",
    "                config[param_name] = np.random.uniform(min_val, max_val)\n",
    "        elif isinstance(param_range, list):\n",
    "            # Discrete choice\n",
    "            config[param_name] = np.random.choice(param_range)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid parameter range type: {type(param_range)}\")\n",
    "    \n",
    "    # Post-process: ensure d_model is divisible by nhead for Transformer\n",
    "    if 'd_model' in config and 'nhead' in config:\n",
    "        config['d_model'] = (config['d_model'] // config['nhead']) * config['nhead']\n",
    "        config['d_model'] = max(config['d_model'], 32)  # Minimum d_model\n",
    "    \n",
    "    return config\n",
    "\n",
    "print(\"Random search sampling function defined!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1652df29",
   "metadata": {},
   "source": [
    "## Data Collection and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e7f97ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data collection function defined!\n"
     ]
    }
   ],
   "source": [
    "def collect_rl_experience(env, vgraph, num_episodes=100, max_steps=200, sequence_len=1):\n",
    "    \"\"\"\n",
    "    Collect expert demonstrations and create temporal sequences.\n",
    "    \n",
    "    Args:\n",
    "        env: Environment instance\n",
    "        vgraph: VisibilityGraph for expert policy\n",
    "        num_episodes: Number of episodes\n",
    "        max_steps: Max steps per episode\n",
    "        sequence_len: Length of temporal sequences\n",
    "    \n",
    "    Returns:\n",
    "        list: Samples with state_sequences, action_sequences, target_action, goal\n",
    "    \"\"\"\n",
    "    episodes = []\n",
    "    successful_episodes = 0\n",
    "    \n",
    "    for ep in tqdm(range(num_episodes), desc='Collecting experience'):\n",
    "        state = env.reset()\n",
    "        goal = env.goal.copy()\n",
    "        prev_action = np.zeros(2)\n",
    "        episode_data = []\n",
    "        \n",
    "        for t in range(max_steps):\n",
    "            current_pos = state[:2]\n",
    "            current_theta = state[2]\n",
    "            \n",
    "            # Fix: Use vgraph.shortest_path() instead of calling vgraph()\n",
    "            path = vgraph.shortest_path(current_pos, goal)\n",
    "            if path is not None and len(path) > 1:\n",
    "                target = np.array(path[1])\n",
    "            else:\n",
    "                target = goal\n",
    "            \n",
    "            direction = target - current_pos\n",
    "            desired_theta = np.arctan2(direction[1], direction[0])\n",
    "            angle_diff = desired_theta - current_theta\n",
    "            angle_diff = (angle_diff + np.pi) % (2 * np.pi) - np.pi\n",
    "            \n",
    "            steering = np.clip(angle_diff * 2.0, env.action_space.low[1], env.action_space.high[1])\n",
    "            dist_to_target = np.linalg.norm(direction)\n",
    "            \n",
    "            if dist_to_target < env.goal_radius * 3:\n",
    "                throttle = env.action_space.high[0] * 0.3\n",
    "            else:\n",
    "                throttle = env.action_space.high[0] * 0.8\n",
    "            \n",
    "            action = np.array([throttle, steering])\n",
    "            action = np.clip(action, env.action_space.low, env.action_space.high)\n",
    "            \n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            episode_data.append({\n",
    "                'state': state.copy(),\n",
    "                'action': action.copy(),\n",
    "            })\n",
    "            \n",
    "            prev_action = action\n",
    "            state = next_state\n",
    "            \n",
    "            if done:\n",
    "                if info.get('reason') == 'goal_reached':\n",
    "                    successful_episodes += 1\n",
    "                break\n",
    "        \n",
    "        if len(episode_data) > 0:\n",
    "            episodes.append({'transitions': episode_data, 'goal': goal})\n",
    "    \n",
    "    # Create sequences from episodes\n",
    "    data = []\n",
    "    for episode in episodes:\n",
    "        transitions = episode['transitions']\n",
    "        goal = episode['goal']\n",
    "        \n",
    "        for i in range(len(transitions)):\n",
    "            # Get sequence history\n",
    "            start_idx = max(0, i - sequence_len + 1)\n",
    "            seq_transitions = transitions[start_idx:i+1]\n",
    "            \n",
    "            # Pad if necessary\n",
    "            while len(seq_transitions) < sequence_len:\n",
    "                seq_transitions.insert(0, {'state': np.zeros_like(transitions[0]['state']), \n",
    "                                           'action': np.zeros_like(transitions[0]['action'])})\n",
    "            \n",
    "            state_seq = np.array([t['state'] for t in seq_transitions[:-1]] + [transitions[i]['state']])\n",
    "            action_seq = np.array([t['action'] for t in seq_transitions[:-1]] + [np.zeros_like(transitions[i]['action'])])\n",
    "            target_action = transitions[i]['action']\n",
    "            \n",
    "            data.append({\n",
    "                'state_sequences': state_seq,\n",
    "                'action_sequences': action_seq,\n",
    "                'target_action': target_action,\n",
    "                'goal': goal,\n",
    "            })\n",
    "    \n",
    "    print(f\"Collected {len(data)} sequence samples from {num_episodes} episodes\")\n",
    "    print(f\"Success rate: {successful_episodes/num_episodes:.2%}\")\n",
    "    return data\n",
    "\n",
    "print(\"Data collection function defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a347d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting new dataset with sequence_len=5...\n",
      "Precomuting visibility graph...\n",
      "\t| Recomputing...\n",
      "\t| Creating grid...\n",
      "\t| Building graph...\n",
      "\t| Computing distances grid...\n",
      "\t| saving to cache...\n",
      "\t| finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting experience: 100%|██████████| 1000/1000 [44:29<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 33007 sequence samples from 1000 episodes\n",
      "Success rate: 0.00%\n",
      "✓ Saved dataset to expert_dataset_seq5.pickle\n",
      "\n",
      "Dataset Summary:\n",
      "  Total sequence samples: 33007\n",
      "  State sequences shape: (33007, 5, 8)  # (samples, seq_len, state_dim)\n",
      "  Action sequences shape: (33007, 5, 2)  # (samples, seq_len, action_dim)\n",
      "  Target actions shape: (33007, 2)  # (samples, action_dim)\n",
      "  Goals shape: (33007, 2)  # (samples, 2)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'expert_dataset_seq5.pickle'  # Using sequence_len=5 for dataset\n",
    "SEQUENCE_LEN = 5  # Default sequence length for data collection\n",
    "\n",
    "if os.path.exists(dataset_path):\n",
    "    print(f\"Loading existing dataset from {dataset_path}...\")\n",
    "    data = load_pickle(dataset_path)\n",
    "    print(f\"✓ Loaded {len(data)} sequence samples\")\n",
    "else:\n",
    "    print(f\"Collecting new dataset with sequence_len={SEQUENCE_LEN}...\")\n",
    "    layout_dict = read_layout_dict('example0')\n",
    "    \n",
    "    # Fix layout_dict - combine start_pos and start_heading into start tuple\n",
    "    if 'start_pos' in layout_dict and 'start_heading' in layout_dict:\n",
    "        start_pos = layout_dict.pop('start_pos')\n",
    "        start_heading = layout_dict.pop('start_heading')\n",
    "        layout_dict['start'] = (*start_pos, start_heading)\n",
    "    elif 'start_pos' in layout_dict:\n",
    "        layout_dict['start'] = layout_dict.pop('start_pos')\n",
    "    \n",
    "    # Remove any keys that aren't valid env parameters\n",
    "    if 'layout' in layout_dict:\n",
    "        layout_dict.pop('layout')\n",
    "    \n",
    "    env_collect = ContinuousNavigationEnv(**layout_dict)\n",
    "    vgraph = VisibilityGraph(env_collect.goal, env_collect.obstacles, env_collect.bounds, resolution=(20, 20))\n",
    "    data = collect_rl_experience(env_collect, vgraph, num_episodes=CONFIG['num_episodes'], \n",
    "                                  max_steps=CONFIG['max_steps'], sequence_len=SEQUENCE_LEN)\n",
    "    save_pickle(data, dataset_path)\n",
    "    print(f\"✓ Saved dataset to {dataset_path}\")\n",
    "\n",
    "state_sequences = np.array([d['state_sequences'] for d in data])\n",
    "action_sequences = np.array([d['action_sequences'] for d in data])\n",
    "target_actions = np.array([d['target_action'] for d in data])\n",
    "goals = np.array([d['goal'] for d in data])\n",
    "\n",
    "print(f\"\\nDataset Summary:\")\n",
    "print(f\"  Total sequence samples: {len(data)}\")\n",
    "print(f\"  State sequences shape: {state_sequences.shape}  # (samples, seq_len, state_dim)\")\n",
    "print(f\"  Action sequences shape: {action_sequences.shape}  # (samples, seq_len, action_dim)\")\n",
    "print(f\"  Target actions shape: {target_actions.shape}  # (samples, action_dim)\")\n",
    "print(f\"  Goals shape: {goals.shape}  # (samples, 2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "741954a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGC-DL-CONTAINER-LICENSE    home\t opt\t\t   sys\n",
      "bin\t\t\t    jupyter.log  proc\t\t   tmp\n",
      "boot\t\t\t    lib\t\t risky_navigation  usr\n",
      "cuda-keyring_1.1-1_all.deb  lib32\t root\t\t   var\n",
      "dev\t\t\t    lib64\t run\t\t   workspace\n",
      "etc\t\t\t    libx32\t sbin\n",
      "expert_dataset_seq5.pickle  media\t srv\n",
      "get-pip.py\t\t    mnt\t\t start.sh\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "437071f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment & Data Configuration:\n",
      "  STATE_DIM = 8\n",
      "  ACTION_DIM = 2\n",
      "  GOAL_DIM = 2\n",
      "  Total samples = 33007\n",
      "  Sequence length used = 5\n",
      "  State space: (8,)\n",
      "  Action space: (2,)\n"
     ]
    }
   ],
   "source": [
    "STATE_DIM = state_sequences.shape[2]  # state dimension from (samples, seq_len, state_dim)\n",
    "ACTION_DIM = target_actions.shape[1]\n",
    "GOAL_DIM = 2\n",
    "layout_dict = read_layout_dict('example0')\n",
    "\n",
    "# Fix layout_dict - combine start_pos and start_heading into start tuple\n",
    "if 'start_pos' in layout_dict and 'start_heading' in layout_dict:\n",
    "    start_pos = layout_dict.pop('start_pos')\n",
    "    start_heading = layout_dict.pop('start_heading')\n",
    "    layout_dict['start'] = (*start_pos, start_heading)\n",
    "elif 'start_pos' in layout_dict:\n",
    "    layout_dict['start'] = layout_dict.pop('start_pos')\n",
    "\n",
    "# Remove any keys that aren't valid env parameters\n",
    "if 'layout' in layout_dict:\n",
    "    layout_dict.pop('layout')\n",
    "\n",
    "env = ContinuousNavigationEnv(**layout_dict)\n",
    "\n",
    "print(f\"Environment & Data Configuration:\")\n",
    "print(f\"  STATE_DIM = {STATE_DIM}\")\n",
    "print(f\"  ACTION_DIM = {ACTION_DIM}\")\n",
    "print(f\"  GOAL_DIM = {GOAL_DIM}\")\n",
    "print(f\"  Total samples = {len(state_sequences)}\")\n",
    "print(f\"  Sequence length used = {state_sequences.shape[1]}\")\n",
    "print(f\"  State space: {env.observation_space.shape}\")\n",
    "print(f\"  Action space: {env.action_space.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d49cc82",
   "metadata": {},
   "source": [
    "## Random Search Training - All Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9da6b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANDOM SEARCH TRAINING - ALL ALGORITHMS\n",
      "============================================================\n",
      "Data split: 26405 train, 6602 val\n",
      "Batch size: 512\n",
      "Max epochs: 200\n",
      "Random trials per algorithm: 50\n",
      "\n",
      "Note: Data collected with sequence_len=5\n",
      "Random search will test different sequence_len by slicing/padding sequences\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"RANDOM SEARCH TRAINING - ALL ALGORITHMS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "GOAL_DIM = 2\n",
    "n_samples = len(state_sequences)\n",
    "n_train = int(n_samples * (1 - CONFIG['val_ratio']))\n",
    "indices = np.random.permutation(n_samples)\n",
    "train_indices = indices[:n_train]\n",
    "val_indices = indices[n_train:]\n",
    "\n",
    "train_state_seqs = state_sequences[train_indices]\n",
    "train_action_seqs = action_sequences[train_indices]\n",
    "train_target_actions = target_actions[train_indices]\n",
    "train_goals = goals[train_indices]\n",
    "\n",
    "val_state_seqs = state_sequences[val_indices]\n",
    "val_action_seqs = action_sequences[val_indices]\n",
    "val_target_actions = target_actions[val_indices]\n",
    "val_goals = goals[val_indices]\n",
    "\n",
    "print(f\"Data split: {len(train_state_seqs)} train, {len(val_state_seqs)} val\")\n",
    "print(f\"Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"Max epochs: {CONFIG['num_epochs']}\")\n",
    "print(f\"Random trials per algorithm: {CONFIG['n_random_trials']}\\n\")\n",
    "\n",
    "random_search_results = {}\n",
    "algorithms_with_search = {\n",
    "    'Linear': (LinearAgent, RANDOM_SEARCH_CONFIGS['Linear']),\n",
    "    'Transformer': (TransformerAgent, RANDOM_SEARCH_CONFIGS['Transformer']),\n",
    "    'Bayesian': (BayesianAgent, RANDOM_SEARCH_CONFIGS['Bayesian']),\n",
    "    'VAE': (VAEAgent, RANDOM_SEARCH_CONFIGS['VAE'])\n",
    "}\n",
    "\n",
    "print(\"Note: Data collected with sequence_len=5\")\n",
    "print(\"Random search will test different sequence_len by slicing/padding sequences\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aed5e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Random Search: Linear\n",
      "============================================================\n",
      "Testing 50 random configurations for Linear...\n",
      "  [1/50] Testing {'sequence_len': 10, 'lr': 0.0006935288092599838}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x2)\n",
      "  [2/50] Testing {'sequence_len': 1, 'lr': 0.0002552476880477854}...\n",
      "    ✓ New best: 0.020501\n",
      "  [3/50] Testing {'sequence_len': 5, 'lr': 0.0005856030068660645}...\n",
      "    ✓ New best: 0.009571\n",
      "  [4/50] Testing {'sequence_len': 1, 'lr': 0.00020816884047349468}...\n",
      "  [5/50] Testing {'sequence_len': 1, 'lr': 0.00046379421969489467}...\n",
      "  [6/50] Testing {'sequence_len': 5, 'lr': 0.00019554388946130992}...\n",
      "  [7/50] Testing {'sequence_len': 1, 'lr': 0.00014059746071491913}...\n",
      "  [8/50] Testing {'sequence_len': 5, 'lr': 0.00042120519680761644}...\n",
      "    ✓ New best: 0.009467\n",
      "  [9/50] Testing {'sequence_len': 5, 'lr': 0.00037514330905119336}...\n",
      "  [10/50] Testing {'sequence_len': 5, 'lr': 0.00042474210928741975}...\n",
      "    ✓ New best: 0.009436\n",
      "  [11/50] Testing {'sequence_len': 5, 'lr': 0.00033120587295331944}...\n",
      "  [12/50] Testing {'sequence_len': 5, 'lr': 0.00017777039497589861}...\n",
      "  [13/50] Testing {'sequence_len': 5, 'lr': 0.0002722049156767145}...\n",
      "  [14/50] Testing {'sequence_len': 1, 'lr': 0.0004200874767695074}...\n",
      "  [15/50] Testing {'sequence_len': 1, 'lr': 0.0008716445192992139}...\n",
      "  [16/50] Testing {'sequence_len': 5, 'lr': 0.00010467419502692027}...\n",
      "  [17/50] Testing {'sequence_len': 5, 'lr': 0.00018356204541147123}...\n",
      "  [18/50] Testing {'sequence_len': 5, 'lr': 0.0001774740267858649}...\n",
      "  [19/50] Testing {'sequence_len': 10, 'lr': 0.00016005302222895764}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x2)\n",
      "  [20/50] Testing {'sequence_len': 10, 'lr': 0.0008045421184368852}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x2)\n",
      "  [21/50] Testing {'sequence_len': 10, 'lr': 0.00011797056980224045}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x2)\n",
      "  [22/50] Testing {'sequence_len': 5, 'lr': 0.000400480414473054}...\n",
      "  [23/50] Testing {'sequence_len': 5, 'lr': 0.0008079276950216151}...\n",
      "    ✓ New best: 0.009308\n",
      "  [24/50] Testing {'sequence_len': 5, 'lr': 0.0009954110043036402}...\n",
      "  [25/50] Testing {'sequence_len': 10, 'lr': 0.00029159812945802596}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x2)\n",
      "  [26/50] Testing {'sequence_len': 1, 'lr': 0.0005398750077877903}...\n",
      "  [27/50] Testing {'sequence_len': 10, 'lr': 0.00014181421862585256}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x2)\n",
      "  [28/50] Testing {'sequence_len': 5, 'lr': 0.00010798060343514225}...\n",
      "  [29/50] Testing {'sequence_len': 5, 'lr': 0.00026747335683905603}...\n",
      "  [30/50] Testing {'sequence_len': 5, 'lr': 0.0005338796005208398}...\n",
      "  [31/50] Testing {'sequence_len': 10, 'lr': 0.00017781194706428346}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x2)\n",
      "  [32/50] Testing {'sequence_len': 5, 'lr': 0.0006113398719693712}...\n",
      "  [33/50] Testing {'sequence_len': 1, 'lr': 0.0005891084003385109}...\n",
      "  [34/50] Testing {'sequence_len': 10, 'lr': 0.00016115866020983635}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x2)\n",
      "  [35/50] Testing {'sequence_len': 10, 'lr': 0.00036786080802248786}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x2)\n",
      "  [36/50] Testing {'sequence_len': 10, 'lr': 0.00022511423198061262}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x2)\n",
      "  [37/50] Testing {'sequence_len': 10, 'lr': 0.00011936024060870402}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x2)\n",
      "  [38/50] Testing {'sequence_len': 10, 'lr': 0.00021985408685145936}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x2)\n",
      "  [39/50] Testing {'sequence_len': 5, 'lr': 0.00011560327620267797}...\n",
      "  [40/50] Testing {'sequence_len': 10, 'lr': 0.00012810977828942334}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x2)\n",
      "  [41/50] Testing {'sequence_len': 5, 'lr': 0.00021406921416897845}...\n",
      "  [42/50] Testing {'sequence_len': 10, 'lr': 0.000801208005570928}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x2)\n",
      "  [43/50] Testing {'sequence_len': 5, 'lr': 0.0005293505882977476}...\n",
      "  [44/50] Testing {'sequence_len': 10, 'lr': 0.0002946062697170232}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x2)\n",
      "  [45/50] Testing {'sequence_len': 5, 'lr': 0.00014333143519880444}...\n",
      "  [46/50] Testing {'sequence_len': 5, 'lr': 0.00012329011797979916}...\n",
      "  [47/50] Testing {'sequence_len': 10, 'lr': 0.0004851172443400204}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x2)\n",
      "  [48/50] Testing {'sequence_len': 5, 'lr': 0.00010802653995436633}...\n",
      "  [49/50] Testing {'sequence_len': 10, 'lr': 0.00010062821862793696}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x2)\n",
      "  [50/50] Testing {'sequence_len': 10, 'lr': 0.00033785011983189836}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x2)\n",
      "\n",
      "Linear Best Config: {'sequence_len': 5, 'lr': 0.0008079276950216151}\n",
      "Linear Best Val Loss: 0.009308\n",
      "Linear Train Time: 4.80s\n",
      "\n",
      "============================================================\n",
      "Random Search: Transformer\n",
      "============================================================\n",
      "Testing 50 random configurations for Transformer...\n",
      "  [1/50] Testing {'d_model': 48, 'nhead': 8, 'num_layers': 2, 'dropout': 0.08598350060651597, 'sequence_len': 10, 'lr': 0.0002231846636479598}...\n",
      "    ✓ New best: 0.000033\n",
      "  [2/50] Testing {'d_model': 72, 'nhead': 4, 'num_layers': 4, 'dropout': 0.13582572037873583, 'sequence_len': 10, 'lr': 0.00010217822437424176}...\n",
      "  [3/50] Testing {'d_model': 52, 'nhead': 4, 'num_layers': 4, 'dropout': 0.07903087739979564, 'sequence_len': 1, 'lr': 0.0007573288481568313}...\n",
      "  [4/50] Testing {'d_model': 80, 'nhead': 4, 'num_layers': 2, 'dropout': 0.07300749692443545, 'sequence_len': 10, 'lr': 0.0003114974954568882}...\n",
      "    ✓ New best: 0.000016\n",
      "  [5/50] Testing {'d_model': 52, 'nhead': 4, 'num_layers': 3, 'dropout': 0.038126046648897766, 'sequence_len': 1, 'lr': 0.00011330930358933783}...\n",
      "  [6/50] Testing {'d_model': 48, 'nhead': 4, 'num_layers': 4, 'dropout': 0.07853204491031969, 'sequence_len': 1, 'lr': 0.0009234425242503276}...\n",
      "  [7/50] Testing {'d_model': 124, 'nhead': 4, 'num_layers': 4, 'dropout': 0.12181208309668082, 'sequence_len': 1, 'lr': 0.0008322365357897948}...\n",
      "  [8/50] Testing {'d_model': 80, 'nhead': 4, 'num_layers': 4, 'dropout': 0.030305990685873543, 'sequence_len': 5, 'lr': 0.0004344164280530046}...\n",
      "    ✓ New best: 0.000010\n",
      "  [9/50] Testing {'d_model': 32, 'nhead': 8, 'num_layers': 2, 'dropout': 0.04938574833658121, 'sequence_len': 10, 'lr': 0.000521441697654624}...\n",
      "  [10/50] Testing {'d_model': 56, 'nhead': 8, 'num_layers': 2, 'dropout': 0.14160848795590802, 'sequence_len': 1, 'lr': 0.0007978404331493714}...\n",
      "  [11/50] Testing {'d_model': 32, 'nhead': 4, 'num_layers': 3, 'dropout': 0.017848629918184034, 'sequence_len': 10, 'lr': 0.0005178906002933511}...\n",
      "    ✓ New best: 0.000008\n",
      "  [12/50] Testing {'d_model': 96, 'nhead': 8, 'num_layers': 2, 'dropout': 0.15537055631338148, 'sequence_len': 10, 'lr': 0.0005153762646156614}...\n",
      "  [13/50] Testing {'d_model': 108, 'nhead': 4, 'num_layers': 3, 'dropout': 0.02502394493805933, 'sequence_len': 5, 'lr': 0.0001100124551531905}...\n",
      "  [14/50] Testing {'d_model': 116, 'nhead': 4, 'num_layers': 2, 'dropout': 0.1380082103446233, 'sequence_len': 5, 'lr': 0.0007598494938175766}...\n",
      "  [15/50] Testing {'d_model': 48, 'nhead': 4, 'num_layers': 2, 'dropout': 0.1580036458059485, 'sequence_len': 5, 'lr': 0.0003997191209533646}...\n",
      "  [16/50] Testing {'d_model': 88, 'nhead': 8, 'num_layers': 4, 'dropout': 0.051226458826204115, 'sequence_len': 1, 'lr': 0.0005933120344608125}...\n",
      "  [17/50] Testing {'d_model': 40, 'nhead': 4, 'num_layers': 4, 'dropout': 0.028151887349851835, 'sequence_len': 5, 'lr': 0.0007173320782984141}...\n",
      "  [18/50] Testing {'d_model': 108, 'nhead': 4, 'num_layers': 2, 'dropout': 0.04136824103615566, 'sequence_len': 5, 'lr': 0.0006059724043870811}...\n",
      "  [19/50] Testing {'d_model': 40, 'nhead': 4, 'num_layers': 3, 'dropout': 0.10310254333536054, 'sequence_len': 10, 'lr': 0.00019607701107848366}...\n",
      "  [20/50] Testing {'d_model': 40, 'nhead': 8, 'num_layers': 4, 'dropout': 0.17526845888665402, 'sequence_len': 1, 'lr': 0.0005534331319462633}...\n",
      "  [21/50] Testing {'d_model': 80, 'nhead': 8, 'num_layers': 2, 'dropout': 0.05364744209520276, 'sequence_len': 10, 'lr': 0.00020204779932522386}...\n",
      "  [22/50] Testing {'d_model': 72, 'nhead': 4, 'num_layers': 3, 'dropout': 0.17783870760520823, 'sequence_len': 10, 'lr': 0.0005207920545099213}...\n",
      "  [23/50] Testing {'d_model': 72, 'nhead': 4, 'num_layers': 3, 'dropout': 0.19733431882381583, 'sequence_len': 10, 'lr': 0.0004008315364372888}...\n",
      "  [24/50] Testing {'d_model': 76, 'nhead': 4, 'num_layers': 2, 'dropout': 0.11389118310712427, 'sequence_len': 10, 'lr': 0.0006562041857303613}...\n",
      "  [25/50] Testing {'d_model': 124, 'nhead': 4, 'num_layers': 2, 'dropout': 0.04700121412106502, 'sequence_len': 10, 'lr': 0.00013894771055957371}...\n",
      "  [26/50] Testing {'d_model': 48, 'nhead': 8, 'num_layers': 4, 'dropout': 0.0034890717528953674, 'sequence_len': 5, 'lr': 0.00046418537891054616}...\n",
      "    ✓ New best: 0.000007\n",
      "  [27/50] Testing {'d_model': 80, 'nhead': 8, 'num_layers': 3, 'dropout': 0.06041004821035816, 'sequence_len': 10, 'lr': 0.00015881431520407924}...\n",
      "  [28/50] Testing {'d_model': 32, 'nhead': 8, 'num_layers': 4, 'dropout': 0.030157370151863306, 'sequence_len': 1, 'lr': 0.000785953273684516}...\n",
      "  [29/50] Testing {'d_model': 96, 'nhead': 8, 'num_layers': 4, 'dropout': 0.14765429170069846, 'sequence_len': 5, 'lr': 0.0008878873819166909}...\n",
      "  [30/50] Testing {'d_model': 48, 'nhead': 4, 'num_layers': 2, 'dropout': 0.060717556713445676, 'sequence_len': 10, 'lr': 0.00018370210401004734}...\n",
      "  [31/50] Testing {'d_model': 112, 'nhead': 4, 'num_layers': 2, 'dropout': 0.03912909905693971, 'sequence_len': 10, 'lr': 0.00011226124421943709}...\n",
      "  [32/50] Testing {'d_model': 104, 'nhead': 8, 'num_layers': 4, 'dropout': 0.1762355622143964, 'sequence_len': 5, 'lr': 0.000730353726746049}...\n",
      "  [33/50] Testing {'d_model': 40, 'nhead': 4, 'num_layers': 2, 'dropout': 0.016452443790940796, 'sequence_len': 5, 'lr': 0.00040158323811675375}...\n",
      "  [34/50] Testing {'d_model': 56, 'nhead': 8, 'num_layers': 2, 'dropout': 0.01208840744315176, 'sequence_len': 1, 'lr': 0.0001155459545648878}...\n",
      "  [35/50] Testing {'d_model': 72, 'nhead': 8, 'num_layers': 4, 'dropout': 0.07754844178047443, 'sequence_len': 10, 'lr': 0.000711516998094881}...\n",
      "  [36/50] Testing {'d_model': 88, 'nhead': 4, 'num_layers': 4, 'dropout': 0.11836604575967456, 'sequence_len': 1, 'lr': 0.0003751982529486417}...\n",
      "  [37/50] Testing {'d_model': 72, 'nhead': 4, 'num_layers': 3, 'dropout': 0.06534923108541095, 'sequence_len': 5, 'lr': 0.00010187120374730786}...\n",
      "  [38/50] Testing {'d_model': 96, 'nhead': 8, 'num_layers': 3, 'dropout': 0.1298532333751433, 'sequence_len': 10, 'lr': 0.0002103727902524719}...\n",
      "  [39/50] Testing {'d_model': 80, 'nhead': 8, 'num_layers': 2, 'dropout': 0.10899270302974906, 'sequence_len': 5, 'lr': 0.0002285873644818471}...\n",
      "  [40/50] Testing {'d_model': 108, 'nhead': 4, 'num_layers': 2, 'dropout': 0.19301147747065017, 'sequence_len': 10, 'lr': 0.00015489583538781237}...\n",
      "  [41/50] Testing {'d_model': 112, 'nhead': 8, 'num_layers': 2, 'dropout': 0.03882145336115335, 'sequence_len': 5, 'lr': 0.00014095462271185676}...\n",
      "    ✓ New best: 0.000006\n",
      "  [42/50] Testing {'d_model': 120, 'nhead': 8, 'num_layers': 3, 'dropout': 0.11946188422144421, 'sequence_len': 1, 'lr': 0.0001227998315694776}...\n",
      "  [43/50] Testing {'d_model': 72, 'nhead': 8, 'num_layers': 2, 'dropout': 0.07765586944740527, 'sequence_len': 1, 'lr': 0.00015660367841832873}...\n",
      "  [44/50] Testing {'d_model': 48, 'nhead': 8, 'num_layers': 4, 'dropout': 0.17617854192730675, 'sequence_len': 5, 'lr': 0.0003445963551718067}...\n",
      "  [45/50] Testing {'d_model': 120, 'nhead': 4, 'num_layers': 4, 'dropout': 0.18622023920681377, 'sequence_len': 1, 'lr': 0.0009083844167452589}...\n",
      "  [46/50] Testing {'d_model': 72, 'nhead': 8, 'num_layers': 2, 'dropout': 0.16951444338899424, 'sequence_len': 10, 'lr': 0.0007549743318437238}...\n",
      "  [47/50] Testing {'d_model': 32, 'nhead': 4, 'num_layers': 4, 'dropout': 0.04781913964460023, 'sequence_len': 5, 'lr': 0.00022292401532106836}...\n",
      "  [48/50] Testing {'d_model': 112, 'nhead': 4, 'num_layers': 4, 'dropout': 0.02877055846092773, 'sequence_len': 10, 'lr': 0.0002241026146506497}...\n",
      "  [49/50] Testing {'d_model': 88, 'nhead': 8, 'num_layers': 3, 'dropout': 0.17497068643256614, 'sequence_len': 10, 'lr': 0.0008243726497706953}...\n",
      "  [50/50] Testing {'d_model': 32, 'nhead': 8, 'num_layers': 3, 'dropout': 0.13984198409060616, 'sequence_len': 5, 'lr': 0.00010118993462610171}...\n",
      "\n",
      "Transformer Best Config: {'d_model': 112, 'nhead': 8, 'num_layers': 2, 'dropout': 0.03882145336115335, 'sequence_len': 5, 'lr': 0.00014095462271185676}\n",
      "Transformer Best Val Loss: 0.000006\n",
      "Transformer Train Time: 10.71s\n",
      "\n",
      "============================================================\n",
      "Random Search: Bayesian\n",
      "============================================================\n",
      "Testing 50 random configurations for Bayesian...\n",
      "  [1/50] Testing {'hidden_dim': 247, 'prior_std': 1.7748769588143136, 'kl_weight': 0.00036256527741779297, 'sequence_len': 1, 'lr': 0.00015795350375912847}...\n",
      "    ✓ New best: 0.137443\n",
      "  [2/50] Testing {'hidden_dim': 93, 'prior_std': 0.8517860550499234, 'kl_weight': 0.0005786870762034411, 'sequence_len': 1, 'lr': 0.000617827149370235}...\n",
      "    ✓ New best: 0.045684\n",
      "  [3/50] Testing {'hidden_dim': 200, 'prior_std': 1.4089062238188164, 'kl_weight': 0.00017703412734753268, 'sequence_len': 1, 'lr': 0.0005754109544483067}...\n",
      "  [4/50] Testing {'hidden_dim': 229, 'prior_std': 1.8150565631369302, 'kl_weight': 1.017041707893768e-05, 'sequence_len': 5, 'lr': 0.00026137119617316396}...\n",
      "  [5/50] Testing {'hidden_dim': 168, 'prior_std': 1.4656191520647308, 'kl_weight': 6.65965460254276e-05, 'sequence_len': 1, 'lr': 0.00015732202273845364}...\n",
      "  [6/50] Testing {'hidden_dim': 93, 'prior_std': 0.5782109329683462, 'kl_weight': 3.1329039748957196e-05, 'sequence_len': 5, 'lr': 0.00034974464347150024}...\n",
      "  [7/50] Testing {'hidden_dim': 154, 'prior_std': 1.2228983730777991, 'kl_weight': 0.00032294944132242424, 'sequence_len': 10, 'lr': 0.00022308021944122356}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x154)\n",
      "  [8/50] Testing {'hidden_dim': 88, 'prior_std': 0.8318192862151773, 'kl_weight': 2.391331355220736e-05, 'sequence_len': 10, 'lr': 0.0005294766973530316}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x88)\n",
      "  [9/50] Testing {'hidden_dim': 256, 'prior_std': 1.4934984414885335, 'kl_weight': 0.00012056323360720352, 'sequence_len': 10, 'lr': 0.00011674947515531354}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x256)\n",
      "  [10/50] Testing {'hidden_dim': 143, 'prior_std': 1.4372718447320592, 'kl_weight': 3.3093251148319165e-05, 'sequence_len': 10, 'lr': 0.000545681168114882}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x143)\n",
      "  [11/50] Testing {'hidden_dim': 167, 'prior_std': 1.6357250457925612, 'kl_weight': 0.0003806641675810628, 'sequence_len': 1, 'lr': 0.00031274157572473916}...\n",
      "  [12/50] Testing {'hidden_dim': 101, 'prior_std': 1.031221759910456, 'kl_weight': 3.3393979792897664e-05, 'sequence_len': 1, 'lr': 0.0004998069783129187}...\n",
      "  [13/50] Testing {'hidden_dim': 91, 'prior_std': 1.8243064563800557, 'kl_weight': 0.0003870121373638783, 'sequence_len': 10, 'lr': 0.000954103250537093}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x91)\n",
      "  [14/50] Testing {'hidden_dim': 184, 'prior_std': 0.559042263837664, 'kl_weight': 5.125126452371425e-05, 'sequence_len': 1, 'lr': 0.0003764330673533697}...\n",
      "    ✓ New best: 0.035634\n",
      "  [15/50] Testing {'hidden_dim': 162, 'prior_std': 1.768536124250366, 'kl_weight': 3.867841487197505e-05, 'sequence_len': 10, 'lr': 0.0001880616398794947}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x162)\n",
      "  [16/50] Testing {'hidden_dim': 236, 'prior_std': 1.9169499295864925, 'kl_weight': 0.0009066569320696465, 'sequence_len': 1, 'lr': 0.00016937684366143867}...\n",
      "  [17/50] Testing {'hidden_dim': 245, 'prior_std': 1.6568342416222617, 'kl_weight': 0.000532121823535736, 'sequence_len': 5, 'lr': 0.000442068449561502}...\n",
      "  [18/50] Testing {'hidden_dim': 211, 'prior_std': 1.6664530693522317, 'kl_weight': 0.0002375555693820614, 'sequence_len': 5, 'lr': 0.00014711941430970246}...\n",
      "  [19/50] Testing {'hidden_dim': 203, 'prior_std': 1.0586906446876574, 'kl_weight': 5.445363455451418e-05, 'sequence_len': 1, 'lr': 0.0002128005592392828}...\n",
      "  [20/50] Testing {'hidden_dim': 163, 'prior_std': 0.8352876011707031, 'kl_weight': 1.6728584561781494e-05, 'sequence_len': 1, 'lr': 0.00018190913531070655}...\n",
      "  [21/50] Testing {'hidden_dim': 179, 'prior_std': 0.5795603198701367, 'kl_weight': 0.0004642964964309873, 'sequence_len': 1, 'lr': 0.0002191399764936594}...\n",
      "  [22/50] Testing {'hidden_dim': 180, 'prior_std': 1.6637767010687776, 'kl_weight': 0.0001123578414388705, 'sequence_len': 5, 'lr': 0.00010432006328724172}...\n",
      "  [23/50] Testing {'hidden_dim': 226, 'prior_std': 1.0746999855232038, 'kl_weight': 5.023430540709166e-05, 'sequence_len': 1, 'lr': 0.00010216319787157113}...\n",
      "  [24/50] Testing {'hidden_dim': 142, 'prior_std': 1.19852333565667, 'kl_weight': 0.00011347952233524782, 'sequence_len': 5, 'lr': 0.00023127182885385351}...\n",
      "  [25/50] Testing {'hidden_dim': 177, 'prior_std': 0.7708607075539671, 'kl_weight': 9.611316499245933e-05, 'sequence_len': 10, 'lr': 0.0002108453989860467}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x177)\n",
      "  [26/50] Testing {'hidden_dim': 200, 'prior_std': 1.9122694436977619, 'kl_weight': 2.0905662097664964e-05, 'sequence_len': 5, 'lr': 0.0005719877491626298}...\n",
      "  [27/50] Testing {'hidden_dim': 131, 'prior_std': 0.6707553622326785, 'kl_weight': 0.00020225323719522497, 'sequence_len': 5, 'lr': 0.0003479460803893234}...\n",
      "  [28/50] Testing {'hidden_dim': 68, 'prior_std': 0.5578692035828776, 'kl_weight': 0.00018003594255285187, 'sequence_len': 5, 'lr': 0.00048226858374870616}...\n",
      "  [29/50] Testing {'hidden_dim': 173, 'prior_std': 1.9567631935904444, 'kl_weight': 0.0002448910561120636, 'sequence_len': 1, 'lr': 0.00023168367258023716}...\n",
      "  [30/50] Testing {'hidden_dim': 182, 'prior_std': 1.3157186630529032, 'kl_weight': 0.0006040830351991211, 'sequence_len': 10, 'lr': 0.00022364800818220907}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x182)\n",
      "  [31/50] Testing {'hidden_dim': 114, 'prior_std': 1.318940333056763, 'kl_weight': 3.658020611915237e-05, 'sequence_len': 1, 'lr': 0.0005108549107913714}...\n",
      "  [32/50] Testing {'hidden_dim': 167, 'prior_std': 1.8820150172493326, 'kl_weight': 4.656847743940963e-05, 'sequence_len': 1, 'lr': 0.00022957560728488426}...\n",
      "  [33/50] Testing {'hidden_dim': 209, 'prior_std': 1.6945071295535206, 'kl_weight': 0.0001349014586366961, 'sequence_len': 10, 'lr': 0.0005749490478912366}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x209)\n",
      "  [34/50] Testing {'hidden_dim': 103, 'prior_std': 1.9314742932096158, 'kl_weight': 0.0009454760763692516, 'sequence_len': 1, 'lr': 0.00010366437476563305}...\n",
      "  [35/50] Testing {'hidden_dim': 207, 'prior_std': 1.7145988798304714, 'kl_weight': 6.532043091521398e-05, 'sequence_len': 10, 'lr': 0.00010783168192336428}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x207)\n",
      "  [36/50] Testing {'hidden_dim': 175, 'prior_std': 1.5061111067361825, 'kl_weight': 0.0005984608268674142, 'sequence_len': 10, 'lr': 0.0009617729480387839}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x175)\n",
      "  [37/50] Testing {'hidden_dim': 80, 'prior_std': 1.6031506916145213, 'kl_weight': 5.171237713745518e-05, 'sequence_len': 1, 'lr': 0.00032109956059909165}...\n",
      "  [38/50] Testing {'hidden_dim': 177, 'prior_std': 1.6618584502858456, 'kl_weight': 9.75507993982434e-05, 'sequence_len': 5, 'lr': 0.00042842649225030837}...\n",
      "  [39/50] Testing {'hidden_dim': 161, 'prior_std': 1.549866131927112, 'kl_weight': 0.00020897519182850867, 'sequence_len': 5, 'lr': 0.00019608835998761553}...\n",
      "  [40/50] Testing {'hidden_dim': 160, 'prior_std': 0.9020053534591128, 'kl_weight': 2.3049082652813358e-05, 'sequence_len': 10, 'lr': 0.00023876131847466752}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x160)\n",
      "  [41/50] Testing {'hidden_dim': 128, 'prior_std': 1.6120857395066268, 'kl_weight': 1.303093546576391e-05, 'sequence_len': 10, 'lr': 0.0002541168538540765}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x128)\n",
      "  [42/50] Testing {'hidden_dim': 242, 'prior_std': 0.5092041150388276, 'kl_weight': 0.00021990565192171445, 'sequence_len': 1, 'lr': 0.00031813218370075025}...\n",
      "  [43/50] Testing {'hidden_dim': 144, 'prior_std': 1.7009531717981037, 'kl_weight': 0.00037482881102216345, 'sequence_len': 1, 'lr': 0.0001492085220167099}...\n",
      "  [44/50] Testing {'hidden_dim': 222, 'prior_std': 1.5020716711467328, 'kl_weight': 0.0008666500624350958, 'sequence_len': 5, 'lr': 0.00024933004921546577}...\n",
      "  [45/50] Testing {'hidden_dim': 236, 'prior_std': 1.1349378646673205, 'kl_weight': 0.0006490841781469753, 'sequence_len': 1, 'lr': 0.0004740559362320685}...\n",
      "  [46/50] Testing {'hidden_dim': 237, 'prior_std': 1.3532349458013389, 'kl_weight': 9.684230643330305e-05, 'sequence_len': 10, 'lr': 0.00038096991039955527}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x237)\n",
      "  [47/50] Testing {'hidden_dim': 238, 'prior_std': 1.7046342001543417, 'kl_weight': 3.766734006445359e-05, 'sequence_len': 1, 'lr': 0.000855014858555364}...\n",
      "  [48/50] Testing {'hidden_dim': 90, 'prior_std': 1.8052048995939698, 'kl_weight': 1.174487003736045e-05, 'sequence_len': 5, 'lr': 0.00023629448883191831}...\n",
      "  [49/50] Testing {'hidden_dim': 106, 'prior_std': 1.1432315690539363, 'kl_weight': 0.00017919146412255382, 'sequence_len': 1, 'lr': 0.0003563674390623374}...\n",
      "  [50/50] Testing {'hidden_dim': 118, 'prior_std': 0.6506480581370073, 'kl_weight': 2.271588143155603e-05, 'sequence_len': 10, 'lr': 0.00019277638310542016}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x118)\n",
      "\n",
      "Bayesian Best Config: {'hidden_dim': 184, 'prior_std': 0.559042263837664, 'kl_weight': 5.125126452371425e-05, 'sequence_len': 1, 'lr': 0.0003764330673533697}\n",
      "Bayesian Best Val Loss: 0.035634\n",
      "Bayesian Train Time: 2.42s\n",
      "\n",
      "============================================================\n",
      "Random Search: VAE\n",
      "============================================================\n",
      "Testing 50 random configurations for VAE...\n",
      "  [1/50] Testing {'latent_dim': 18, 'hidden_dim': 240, 'beta': 0.5189790725634912, 'sequence_len': 1, 'lr': 0.0001277618947538782}...\n",
      "    ✓ New best: 0.074714\n",
      "  [2/50] Testing {'latent_dim': 21, 'hidden_dim': 110, 'beta': 0.6496334184010276, 'sequence_len': 5, 'lr': 0.0002106420361110957}...\n",
      "    ✓ New best: 0.068870\n",
      "  [3/50] Testing {'latent_dim': 17, 'hidden_dim': 67, 'beta': 1.8741000343793743, 'sequence_len': 10, 'lr': 0.0004147775050126256}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x67)\n",
      "  [4/50] Testing {'latent_dim': 19, 'hidden_dim': 224, 'beta': 1.7518464857384362, 'sequence_len': 5, 'lr': 0.0005175165974465206}...\n",
      "  [5/50] Testing {'latent_dim': 47, 'hidden_dim': 255, 'beta': 0.9702803175574735, 'sequence_len': 1, 'lr': 0.0001623598142302138}...\n",
      "  [6/50] Testing {'latent_dim': 24, 'hidden_dim': 146, 'beta': 1.8281868823078247, 'sequence_len': 10, 'lr': 0.00010458924732465232}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x146)\n",
      "  [7/50] Testing {'latent_dim': 59, 'hidden_dim': 245, 'beta': 1.1130358263651021, 'sequence_len': 10, 'lr': 0.0003442170425697069}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x245)\n",
      "  [8/50] Testing {'latent_dim': 38, 'hidden_dim': 168, 'beta': 1.0532102716854066, 'sequence_len': 5, 'lr': 0.0001838553145260521}...\n",
      "  [9/50] Testing {'latent_dim': 54, 'hidden_dim': 97, 'beta': 1.14848908586968, 'sequence_len': 10, 'lr': 0.0004542691081381255}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x97)\n",
      "  [10/50] Testing {'latent_dim': 54, 'hidden_dim': 136, 'beta': 1.9351637519887315, 'sequence_len': 5, 'lr': 0.00024382453251282582}...\n",
      "  [11/50] Testing {'latent_dim': 46, 'hidden_dim': 130, 'beta': 0.6575808069003788, 'sequence_len': 10, 'lr': 0.0004708034212528788}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x130)\n",
      "  [12/50] Testing {'latent_dim': 41, 'hidden_dim': 103, 'beta': 1.1037888959002613, 'sequence_len': 10, 'lr': 0.00011202252585463396}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x103)\n",
      "  [13/50] Testing {'latent_dim': 38, 'hidden_dim': 115, 'beta': 0.9866416200230506, 'sequence_len': 1, 'lr': 0.0002703005573436256}...\n",
      "  [14/50] Testing {'latent_dim': 29, 'hidden_dim': 199, 'beta': 1.7053960261499446, 'sequence_len': 10, 'lr': 0.00035474072317463246}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x199)\n",
      "  [15/50] Testing {'latent_dim': 62, 'hidden_dim': 65, 'beta': 1.2440256222731343, 'sequence_len': 10, 'lr': 0.0007928924591692796}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x65)\n",
      "  [16/50] Testing {'latent_dim': 41, 'hidden_dim': 128, 'beta': 1.6964231585712413, 'sequence_len': 5, 'lr': 0.00012311635245709754}...\n",
      "  [17/50] Testing {'latent_dim': 47, 'hidden_dim': 100, 'beta': 1.35728719591221, 'sequence_len': 1, 'lr': 0.0003016550113556583}...\n",
      "  [18/50] Testing {'latent_dim': 23, 'hidden_dim': 79, 'beta': 1.8948214037253617, 'sequence_len': 5, 'lr': 0.000907686943582833}...\n",
      "  [19/50] Testing {'latent_dim': 63, 'hidden_dim': 157, 'beta': 1.7085486342758223, 'sequence_len': 10, 'lr': 0.00014491417061558077}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x157)\n",
      "  [20/50] Testing {'latent_dim': 22, 'hidden_dim': 126, 'beta': 1.9535565545943023, 'sequence_len': 10, 'lr': 0.0006204667052487157}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x126)\n",
      "  [21/50] Testing {'latent_dim': 57, 'hidden_dim': 216, 'beta': 0.5656381460186966, 'sequence_len': 1, 'lr': 0.00016654458405045074}...\n",
      "  [22/50] Testing {'latent_dim': 51, 'hidden_dim': 255, 'beta': 1.1395203799768856, 'sequence_len': 5, 'lr': 0.00013745006163212693}...\n",
      "  [23/50] Testing {'latent_dim': 55, 'hidden_dim': 225, 'beta': 1.1452688948608656, 'sequence_len': 10, 'lr': 0.00010340176223954666}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x225)\n",
      "  [24/50] Testing {'latent_dim': 22, 'hidden_dim': 207, 'beta': 1.2260756319133594, 'sequence_len': 10, 'lr': 0.0005249998421180867}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x207)\n",
      "  [25/50] Testing {'latent_dim': 57, 'hidden_dim': 149, 'beta': 1.2544038215892344, 'sequence_len': 1, 'lr': 0.00018715187123501787}...\n",
      "  [26/50] Testing {'latent_dim': 19, 'hidden_dim': 91, 'beta': 0.8995471592361132, 'sequence_len': 5, 'lr': 0.00010390219911149144}...\n",
      "  [27/50] Testing {'latent_dim': 43, 'hidden_dim': 126, 'beta': 1.9809998135304043, 'sequence_len': 1, 'lr': 0.0009595228498941472}...\n",
      "  [28/50] Testing {'latent_dim': 51, 'hidden_dim': 127, 'beta': 1.885861457694094, 'sequence_len': 10, 'lr': 0.00019956285516092178}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x127)\n",
      "  [29/50] Testing {'latent_dim': 64, 'hidden_dim': 208, 'beta': 1.872022181174179, 'sequence_len': 1, 'lr': 0.0006756515056065638}...\n",
      "  [30/50] Testing {'latent_dim': 18, 'hidden_dim': 132, 'beta': 0.6257703289467376, 'sequence_len': 1, 'lr': 0.00028862272995490743}...\n",
      "  [31/50] Testing {'latent_dim': 47, 'hidden_dim': 190, 'beta': 1.475345514842017, 'sequence_len': 1, 'lr': 0.0006214674039079927}...\n",
      "  [32/50] Testing {'latent_dim': 60, 'hidden_dim': 225, 'beta': 0.7254377778308865, 'sequence_len': 5, 'lr': 0.00026637290737828835}...\n",
      "  [33/50] Testing {'latent_dim': 52, 'hidden_dim': 152, 'beta': 1.3767531676203921, 'sequence_len': 5, 'lr': 0.0001466939874946583}...\n",
      "  [34/50] Testing {'latent_dim': 38, 'hidden_dim': 67, 'beta': 1.213227894143513, 'sequence_len': 5, 'lr': 0.0005052810880485999}...\n",
      "  [35/50] Testing {'latent_dim': 50, 'hidden_dim': 216, 'beta': 1.5496033830605807, 'sequence_len': 5, 'lr': 0.0004049581405500823}...\n",
      "  [36/50] Testing {'latent_dim': 44, 'hidden_dim': 146, 'beta': 0.9865360328675468, 'sequence_len': 10, 'lr': 0.00010043410509783542}...\n",
      "    ✗ Failed: mat1 and mat2 shapes cannot be multiplied (512x52 and 102x146)\n",
      "  [37/50] Testing {'latent_dim': 42, 'hidden_dim': 203, 'beta': 1.470602739156478, 'sequence_len': 1, 'lr': 0.0007233134732021937}...\n",
      "  [38/50] Testing {'latent_dim': 17, 'hidden_dim': 245, 'beta': 0.9688978168815181, 'sequence_len': 5, 'lr': 0.0001622845307460288}...\n"
     ]
    }
   ],
   "source": [
    "for alg_name, (AgentClass, param_ranges) in algorithms_with_search.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Random Search: {alg_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    n_trials = CONFIG['n_random_trials']\n",
    "    print(f\"Testing {n_trials} random configurations for {alg_name}...\")\n",
    "    \n",
    "    best_config = None\n",
    "    best_val_loss = float('inf')\n",
    "    best_agent = None\n",
    "    best_train_time = 0\n",
    "    all_configs = []\n",
    "    \n",
    "    for trial_idx in range(n_trials):\n",
    "        # Sample random configuration\n",
    "        config = sample_random_config(param_ranges)\n",
    "        all_configs.append(config)\n",
    "        \n",
    "        print(f\"  [{trial_idx+1}/{n_trials}] Testing {config}...\")\n",
    "        \n",
    "        try:\n",
    "            # Prepare data for this sequence_len\n",
    "            config_seq_len = config.get('sequence_len', 1)\n",
    "            data_seq_len = train_state_seqs.shape[1]\n",
    "            \n",
    "            # Slice or pad sequences to match config\n",
    "            if config_seq_len <= data_seq_len:\n",
    "                train_seqs_adj = train_state_seqs[:, -config_seq_len:, :]\n",
    "                train_acts_adj = train_action_seqs[:, -config_seq_len:, :]\n",
    "                val_seqs_adj = val_state_seqs[:, -config_seq_len:, :]\n",
    "                val_acts_adj = val_action_seqs[:, -config_seq_len:, :]\n",
    "            else:\n",
    "                # Pad if needed (shouldn't happen with current setup)\n",
    "                train_seqs_adj = train_state_seqs\n",
    "                train_acts_adj = train_action_seqs\n",
    "                val_seqs_adj = val_state_seqs\n",
    "                val_acts_adj = val_action_seqs\n",
    "            \n",
    "            agent = AgentClass(\n",
    "                state_dim=STATE_DIM,\n",
    "                action_dim=ACTION_DIM,\n",
    "                goal_dim=GOAL_DIM,\n",
    "                **config,\n",
    "                device=CONFIG['device'],\n",
    "                action_low=env.action_space.low,\n",
    "                action_high=env.action_space.high\n",
    "            )\n",
    "            \n",
    "            start_time = time.time()\n",
    "            train_losses, val_losses = train_agent_optimized(\n",
    "                agent,\n",
    "                train_seqs_adj, train_acts_adj, train_target_actions, train_goals,\n",
    "                val_seqs_adj, val_acts_adj, val_target_actions, val_goals,\n",
    "                num_epochs=CONFIG['num_epochs'],\n",
    "                batch_size=CONFIG['batch_size'],\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "            val_loss = min(val_losses) if val_losses else float('inf')\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_config = config\n",
    "                best_agent = agent\n",
    "                best_train_time = elapsed_time\n",
    "                print(f\"    ✓ New best: {val_loss:.6f}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"    ✗ Failed: {e}\")\n",
    "            continue\n",
    "    \n",
    "    random_search_results[alg_name] = {\n",
    "        'best_config': best_config,\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'best_agent': best_agent,\n",
    "        'train_time': best_train_time,\n",
    "        'all_configs': all_configs\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{alg_name} Best Config: {best_config}\")\n",
    "    print(f\"{alg_name} Best Val Loss: {best_val_loss:.6f}\")\n",
    "    print(f\"{alg_name} Train Time: {best_train_time:.2f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RANDOM SEARCH COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "for alg_name, result in random_search_results.items():\n",
    "    print(f\"{alg_name:12} | Val Loss: {result['best_val_loss']:.6f} | Time: {result['train_time']:.2f}s\")\n",
    "    print(f\"             | Config: {result['best_config']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507cee6b",
   "metadata": {},
   "source": [
    "## Evaluate Best Models from Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dfdccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EVALUATING BEST MODELS FROM RANDOM SEARCH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def evaluate_agent_optimized(agent, env, num_episodes=50, max_steps=200, device='cpu'):\n",
    "    \"\"\"\n",
    "    Clean evaluation function without fallback mechanisms.\n",
    "    All agents must have sequence_len attribute.\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'rewards': [], \n",
    "        'successes': [], \n",
    "        'steps': [],\n",
    "        'final_distances': [],\n",
    "        'final_velocities': []\n",
    "    }\n",
    "    \n",
    "    # All agents must have sequence_len attribute\n",
    "    sequence_len = agent.sequence_len\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        goal = env.goal.copy()  # Environment always has goal\n",
    "        episode_reward = 0\n",
    "        done = False\n",
    "        \n",
    "        # Initialize sequence history\n",
    "        state_history = [np.zeros_like(state) for _ in range(sequence_len)]\n",
    "        action_history = [np.zeros(ACTION_DIM) for _ in range(sequence_len)]\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            # Update history\n",
    "            state_history.append(state.copy())\n",
    "            state_history.pop(0)\n",
    "            \n",
    "            # Create sequences\n",
    "            state_seq = np.array(state_history)\n",
    "            action_seq = np.array(action_history)\n",
    "            \n",
    "            state_seq_t = torch.tensor(state_seq, dtype=torch.float32, device=device)\n",
    "            action_seq_t = torch.tensor(action_seq, dtype=torch.float32, device=device)\n",
    "            goal_t = torch.tensor(goal, dtype=torch.float32, device=device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                action = agent.predict_action(state_seq_t, action_seq_t, goal_t)\n",
    "            \n",
    "            if isinstance(action, torch.Tensor):\n",
    "                action = action.cpu().numpy()\n",
    "            \n",
    "            # Update action history\n",
    "            action_history.append(action.copy())\n",
    "            action_history.pop(0)\n",
    "            \n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            episode_reward += reward\n",
    "            state = next_state\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        results['rewards'].append(episode_reward)\n",
    "        success = info.get('reason', '') == 'goal_reached' if done else False\n",
    "        results['successes'].append(1 if success else 0)\n",
    "        results['steps'].append(step + 1)\n",
    "        results['final_distances'].append(np.linalg.norm(state[:2] - goal))\n",
    "        results['final_velocities'].append(state[3])\n",
    "    \n",
    "    return {\n",
    "        'avg_reward': np.mean(results['rewards']),\n",
    "        'success_rate': np.mean(results['successes']),\n",
    "        'avg_steps': np.mean(results['steps']),\n",
    "        'avg_final_dist': np.mean(results['final_distances']),\n",
    "        'avg_final_vel': np.mean(results['final_velocities'])\n",
    "    }\n",
    "\n",
    "eval_results = {}\n",
    "layout_dict_eval = read_layout_dict('example0')\n",
    "\n",
    "# Fix layout_dict - combine start_pos and start_heading into start tuple\n",
    "if 'start_pos' in layout_dict_eval and 'start_heading' in layout_dict_eval:\n",
    "    start_pos = layout_dict_eval.pop('start_pos')\n",
    "    start_heading = layout_dict_eval.pop('start_heading')\n",
    "    layout_dict_eval['start'] = (*start_pos, start_heading)\n",
    "elif 'start_pos' in layout_dict_eval:\n",
    "    layout_dict_eval['start'] = layout_dict_eval.pop('start_pos')\n",
    "\n",
    "# Remove any keys that aren't valid env parameters\n",
    "if 'layout' in layout_dict_eval:\n",
    "    layout_dict_eval.pop('layout')\n",
    "\n",
    "env_eval = ContinuousNavigationEnv(**layout_dict_eval)\n",
    "\n",
    "for alg_name, result in random_search_results.items():\n",
    "    agent = result['best_agent']\n",
    "    print(f\"\\nEvaluating {alg_name}...\")\n",
    "    eval_res = evaluate_agent_optimized(agent, env_eval, num_episodes=CONFIG['num_test_episodes'], device=CONFIG['device'])\n",
    "    eval_results[alg_name] = eval_res\n",
    "    print(f\"{alg_name} - Success: {eval_res['success_rate']:.1%}, Avg Reward: {eval_res['avg_reward']:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION COMPLETE\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791f2f13",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3cc541",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_data = []\n",
    "for alg_name, result in random_search_results.items():\n",
    "    eval_res = eval_results[alg_name]\n",
    "    results_data.append({\n",
    "        'Algorithm': alg_name,\n",
    "        'Val Loss': result['best_val_loss'],\n",
    "        'Train Time (s)': result['train_time'],\n",
    "        'Success Rate': eval_res['success_rate'],\n",
    "        'Avg Reward': eval_res['avg_reward'],\n",
    "        'Avg Steps': eval_res['avg_steps'],\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results_data)\n",
    "df_results = df_results.sort_values('Val Loss')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(df_results.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "axes[0, 0].bar(df_results['Algorithm'], df_results['Success Rate'], color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_ylabel('Success Rate')\n",
    "axes[0, 0].set_title('Success Rate by Algorithm')\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "axes[0, 0].set_ylim([0, 1.1])\n",
    "\n",
    "axes[0, 1].bar(df_results['Algorithm'], df_results['Avg Reward'], color='lightgreen', edgecolor='black')\n",
    "axes[0, 1].set_ylabel('Average Reward')\n",
    "axes[0, 1].set_title('Average Reward by Algorithm')\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "axes[1, 0].bar(df_results['Algorithm'], df_results['Val Loss'], color='salmon', edgecolor='black')\n",
    "axes[1, 0].set_ylabel('Validation Loss')\n",
    "axes[1, 0].set_title('Validation Loss by Algorithm')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "axes[1, 0].set_yscale('log')\n",
    "\n",
    "axes[1, 1].bar(df_results['Algorithm'], df_results['Train Time (s)'], color='plum', edgecolor='black')\n",
    "axes[1, 1].set_ylabel('Training Time (s)')\n",
    "axes[1, 1].set_title('Training Time by Algorithm')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf01ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'trained_models/random_search_best'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for alg_name, result in random_search_results.items():\n",
    "    agent = result['best_agent']\n",
    "    model_path = os.path.join(save_dir, f'{alg_name}_best.pth')\n",
    "    \n",
    "    if hasattr(agent, 'model'):\n",
    "        torch.save(agent.model.state_dict(), model_path)\n",
    "    elif hasattr(agent, 'encoder'):\n",
    "        torch.save({'encoder': agent.encoder.state_dict(), 'decoder': agent.decoder.state_dict()}, model_path)\n",
    "    \n",
    "    config_path = os.path.join(save_dir, f'{alg_name}_config.pkl')\n",
    "    save_pickle({\n",
    "        'config': result['best_config'],\n",
    "        'val_loss': result['best_val_loss'],\n",
    "        'train_time': result['train_time'],\n",
    "        'eval_results': eval_results[alg_name],\n",
    "        'all_configs': result['all_configs']  # Save all tested configs for analysis\n",
    "    }, config_path)\n",
    "\n",
    "print(f\"Models and configs saved to {save_dir}/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a54fcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize performance comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "algorithms = list(random_search_results.keys())\n",
    "val_losses = [random_search_results[alg]['best_val_loss'] for alg in algorithms]\n",
    "train_times = [random_search_results[alg]['train_time'] for alg in algorithms]\n",
    "success_rates = [eval_results[alg]['success_rate'] for alg in algorithms]\n",
    "avg_rewards = [eval_results[alg]['avg_reward'] for alg in algorithms]\n",
    "\n",
    "axes[0, 0].bar(algorithms, success_rates, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_ylabel('Success Rate', fontsize=12)\n",
    "axes[0, 0].set_title('Success Rate by Algorithm', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "axes[0, 0].set_ylim([0, 1.1])\n",
    "\n",
    "axes[0, 1].bar(algorithms, avg_rewards, color='lightgreen', edgecolor='black')\n",
    "axes[0, 1].set_ylabel('Average Reward', fontsize=12)\n",
    "axes[0, 1].set_title('Average Reward by Algorithm', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "axes[1, 0].bar(algorithms, val_losses, color='salmon', edgecolor='black')\n",
    "axes[1, 0].set_ylabel('Validation Loss', fontsize=12)\n",
    "axes[1, 0].set_title('Validation Loss by Algorithm', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "axes[1, 0].set_yscale('log')\n",
    "\n",
    "axes[1, 1].bar(algorithms, train_times, color='plum', edgecolor='black')\n",
    "axes[1, 1].set_ylabel('Training Time (s)', fontsize=12)\n",
    "axes[1, 1].set_title('Training Time by Algorithm', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULTS SUMMARY (Random Search)\")\n",
    "print(\"=\"*80)\n",
    "for alg in algorithms:\n",
    "    print(f\"\\n{alg}:\")\n",
    "    print(f\"  Best Config: {random_search_results[alg]['best_config']}\")\n",
    "    print(f\"  Validation Loss: {random_search_results[alg]['best_val_loss']:.6f}\")\n",
    "    print(f\"  Training Time: {random_search_results[alg]['train_time']:.2f}s\")\n",
    "    print(f\"  Success Rate: {eval_results[alg]['success_rate']:.1%}\")\n",
    "    print(f\"  Avg Reward: {eval_results[alg]['avg_reward']:.2f}\")\n",
    "    print(f\"  Avg Steps: {eval_results[alg]['avg_steps']:.1f}\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nNote: Each algorithm tested {CONFIG['n_random_trials']} random configurations\")\n",
    "print(f\"Total configurations tested: {CONFIG['n_random_trials'] * len(algorithms)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
